{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "20368ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader\n",
    "from pprint import pprint\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from conll import evaluate\n",
    "from sklearn.metrics import classification_report\n",
    "import random\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from statistics import mean\n",
    "\n",
    "PAD_TOKEN=0\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be059ede",
   "metadata": {},
   "source": [
    "# 1) Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de211b5",
   "metadata": {},
   "source": [
    "### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b187b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    '''\n",
    "        input: path/to/data\n",
    "        output: json \n",
    "    '''\n",
    "    dataset = []\n",
    "    with open(path) as f:\n",
    "        dataset = json.loads(f.read())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adb03e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATIS_tmp_train_raw = load_data(os.path.join('data','ATIS','train.json'))\n",
    "ATIS_test_raw = load_data(os.path.join('data','ATIS','test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae958228",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNIPS_train_raw = load_data(os.path.join('data','SNIPS','train.json'))\n",
    "SNIPS_dev_raw= load_data(os.path.join('data','SNIPS','valid.json'))\n",
    "SNIPS_test_raw = load_data(os.path.join('data','SNIPS','test.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd0c68b",
   "metadata": {},
   "source": [
    "### Sentence length analysis\n",
    "Visualizing the max length and the length distribution of the dataset, will be useful for setting max_length parameter in the Bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fb9501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_count(samples_count,sent_length):\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    plt.xticks(sent_length)\n",
    "    plt.bar(sent_length,samples_count,width=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69abc9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_length=50\n",
    "ATIS_count=[]\n",
    "SNIPS_count=[]\n",
    "total_count=[]\n",
    "sent_length=[]\n",
    "for i in range(0,plot_length+1):\n",
    "    ATIS_count.append(0)\n",
    "    SNIPS_count.append(0)\n",
    "    total_count.append(0)\n",
    "    sent_length.append(i)\n",
    "\n",
    "ATIS_dataset=ATIS_tmp_train_raw+ATIS_test_raw\n",
    "SNIPS_dataset=SNIPS_train_raw+SNIPS_dev_raw+SNIPS_test_raw\n",
    "total_dataset=ATIS_dataset+SNIPS_dataset\n",
    "\n",
    "for sample in ATIS_dataset:\n",
    "    utterance=sample['utterance'].split()\n",
    "    sent_len=len(utterance)\n",
    "    ATIS_count[sent_len]+=1\n",
    "\n",
    "plot_count(ATIS_count,sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a94dda6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in SNIPS_dataset:\n",
    "    utterance=sample['utterance'].split()\n",
    "    sent_len=len(utterance)\n",
    "    SNIPS_count[sent_len]+=1\n",
    "\n",
    "plot_count(SNIPS_count,sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6def38b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sample in total_dataset:\n",
    "    utterance=sample['utterance'].split()\n",
    "    sent_len=len(utterance)\n",
    "    total_count[sent_len]+=1\n",
    "\n",
    "plot_count(total_count,sent_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0baee05",
   "metadata": {},
   "source": [
    "### Create development set\n",
    "\n",
    "As suggested in class, we create a development set used for hyperparameter tuning using a stratification strategy in order to preserve the intents data distributions.\n",
    "Since SNIPS dataset already comes with a validation set, the development set for this dataset is not created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "425cb1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "{'abbreviation': 2.9000000000000004,\n",
      " 'aircraft': 1.6,\n",
      " 'airfare': 8.5,\n",
      " 'airline': 3.2,\n",
      " 'airline+flight_no': 0.0,\n",
      " 'airport': 0.4,\n",
      " 'capacity': 0.3,\n",
      " 'city': 0.4,\n",
      " 'distance': 0.4,\n",
      " 'flight': 73.7,\n",
      " 'flight+airfare': 0.4,\n",
      " 'flight_no': 0.3,\n",
      " 'flight_time': 1.0999999999999999,\n",
      " 'ground_fare': 0.4,\n",
      " 'ground_service': 5.1,\n",
      " 'meal': 0.1,\n",
      " 'quantity': 1.0,\n",
      " 'restriction': 0.1}\n",
      "Dev:\n",
      "{'abbreviation': 3.0,\n",
      " 'aircraft': 1.7000000000000002,\n",
      " 'airfare': 8.5,\n",
      " 'airline': 3.2,\n",
      " 'airport': 0.3,\n",
      " 'capacity': 0.3,\n",
      " 'city': 0.3,\n",
      " 'distance': 0.3,\n",
      " 'flight': 73.7,\n",
      " 'flight+airfare': 0.5,\n",
      " 'flight_no': 0.2,\n",
      " 'flight_time': 1.0,\n",
      " 'ground_fare': 0.3,\n",
      " 'ground_service': 5.2,\n",
      " 'meal': 0.2,\n",
      " 'quantity': 1.0,\n",
      " 'restriction': 0.2}\n",
      "Test:\n",
      "{'abbreviation': 3.6999999999999997,\n",
      " 'aircraft': 1.0,\n",
      " 'airfare': 5.4,\n",
      " 'airfare+flight': 0.1,\n",
      " 'airline': 4.3,\n",
      " 'airport': 2.0,\n",
      " 'capacity': 2.4,\n",
      " 'city': 0.7000000000000001,\n",
      " 'day_name': 0.2,\n",
      " 'distance': 1.0999999999999999,\n",
      " 'flight': 70.8,\n",
      " 'flight+airfare': 1.3,\n",
      " 'flight+airline': 0.1,\n",
      " 'flight_no': 0.8999999999999999,\n",
      " 'flight_no+airline': 0.1,\n",
      " 'flight_time': 0.1,\n",
      " 'ground_fare': 0.8,\n",
      " 'ground_service': 4.0,\n",
      " 'meal': 0.7000000000000001,\n",
      " 'quantity': 0.3}\n",
      "=========================================================================================\n",
      "TRAIN size: 4381\n",
      "DEV size: 597\n",
      "TEST size: 893\n"
     ]
    }
   ],
   "source": [
    "#ATIS\n",
    "# Firt we get the 10% of dataset, then we compute the percentage of these examples \n",
    "# on the training set which is around 11% \n",
    "portion = round(((len(ATIS_tmp_train_raw) + len(ATIS_test_raw)) * 0.10)/(len(ATIS_tmp_train_raw)),2)\n",
    "\n",
    "intents = [x['intent'] for x in ATIS_tmp_train_raw] # We stratify on intents\n",
    "count_y = Counter(intents)#For each class count the appearances\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "mini_Train = []\n",
    "\n",
    "for id_y, y in enumerate(intents):\n",
    "    if count_y[y] > 1: # Some intents have only one instance, we put them in training\n",
    "        X.append(ATIS_tmp_train_raw[id_y])\n",
    "        Y.append(y)\n",
    "    else:\n",
    "        mini_Train.append(ATIS_tmp_train_raw[id_y])\n",
    "# Random Stratify\n",
    "ATIS_X_train, ATIS_X_dev, ATIS_y_train, ATIS_y_dev = train_test_split(X, Y, test_size=portion, \n",
    "                                                    random_state=42, \n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=Y)\n",
    "ATIS_X_train.extend(mini_Train)\n",
    "ATIS_train_raw = ATIS_X_train\n",
    "ATIS_dev_raw = ATIS_X_dev\n",
    "\n",
    "ATIS_y_test = [x['intent'] for x in ATIS_test_raw]\n",
    "\n",
    "# Intent distribution\n",
    "print('Train:')\n",
    "pprint({k:round(v/len(ATIS_y_train),3)*100 for k, v in sorted(Counter(ATIS_y_train).items())})\n",
    "print('Dev:'), \n",
    "pprint({k:round(v/len(ATIS_y_dev),3)*100 for k, v in sorted(Counter(ATIS_y_dev).items())})\n",
    "print('Test:') \n",
    "pprint({k:round(v/len(ATIS_y_test),3)*100 for k, v in sorted(Counter(ATIS_y_test).items())})\n",
    "print('='*89)\n",
    "# Dataset size\n",
    "print('TRAIN size:', len(ATIS_train_raw))\n",
    "print('DEV size:', len(ATIS_dev_raw))\n",
    "print('TEST size:', len(ATIS_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ffe521b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNIPS\n",
      "TRAIN size: 13084\n",
      "DEV size: 700\n",
      "TEST size: 700\n",
      "Train:\n",
      "{'AddToPlaylist': 13.900000000000002,\n",
      " 'BookRestaurant': 14.399999999999999,\n",
      " 'GetWeather': 14.499999999999998,\n",
      " 'PlayMusic': 14.6,\n",
      " 'RateBook': 14.299999999999999,\n",
      " 'SearchCreativeWork': 14.099999999999998,\n",
      " 'SearchScreeningEvent': 14.2}\n",
      "Dev:\n",
      "{'AddToPlaylist': 14.299999999999999,\n",
      " 'BookRestaurant': 14.299999999999999,\n",
      " 'GetWeather': 14.299999999999999,\n",
      " 'PlayMusic': 14.299999999999999,\n",
      " 'RateBook': 14.299999999999999,\n",
      " 'SearchCreativeWork': 14.299999999999999,\n",
      " 'SearchScreeningEvent': 14.299999999999999}\n",
      "Test:\n",
      "{'AddToPlaylist': 17.7,\n",
      " 'BookRestaurant': 13.100000000000001,\n",
      " 'GetWeather': 14.899999999999999,\n",
      " 'PlayMusic': 12.3,\n",
      " 'RateBook': 11.4,\n",
      " 'SearchCreativeWork': 15.299999999999999,\n",
      " 'SearchScreeningEvent': 15.299999999999999}\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('SNIPS')\n",
    "print('TRAIN size:', len(SNIPS_train_raw))\n",
    "print('DEV size:', len(SNIPS_dev_raw))\n",
    "print('TEST size:', len(SNIPS_test_raw))\n",
    "\n",
    "SNIPS_intent_train=[]\n",
    "SNIPS_intent_dev=[]\n",
    "SNIPS_intent_test=[]\n",
    "\n",
    "for sample in SNIPS_train_raw:\n",
    "    SNIPS_intent_train.append(sample['intent'])\n",
    "\n",
    "for sample in SNIPS_dev_raw:\n",
    "    SNIPS_intent_dev.append(sample['intent'])\n",
    "\n",
    "for sample in SNIPS_test_raw:\n",
    "    SNIPS_intent_test.append(sample['intent'])\n",
    "\n",
    "# Intent distribution\n",
    "print('Train:')\n",
    "pprint({k:round(v/len(SNIPS_intent_train),3)*100 for k, v in sorted(Counter(SNIPS_intent_train).items())})\n",
    "print('Dev:'), \n",
    "pprint({k:round(v/len(SNIPS_intent_dev),3)*100 for k, v in sorted(Counter(SNIPS_intent_dev).items())})\n",
    "print('Test:') \n",
    "pprint({k:round(v/len(SNIPS_intent_test),3)*100 for k, v in sorted(Counter(SNIPS_intent_test).items())})\n",
    "print('='*89)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f8683d",
   "metadata": {},
   "source": [
    "### Lang Class\n",
    "\n",
    "Class handling conversion of words/slots/intents to ids and viceversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f33348ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang():\n",
    "    def __init__(self, words, intents, slots, cutoff=0):\n",
    "        self.word2id = self.w2id(words, cutoff=cutoff, unk=True)\n",
    "        self.slot2id = self.lab2id(slots)\n",
    "        self.intent2id = self.lab2id(intents, pad=False)\n",
    "        self.id2word = {v:k for k, v in self.word2id.items()}\n",
    "        self.id2slot = {v:k for k, v in self.slot2id.items()}\n",
    "        self.id2intent = {v:k for k, v in self.intent2id.items()}\n",
    "        \n",
    "    def w2id(self, elements, cutoff=None, unk=True):\n",
    "        vocab = {'pad': PAD_TOKEN}\n",
    "        if unk:\n",
    "            vocab['unk'] = len(vocab)\n",
    "        count = Counter(elements)\n",
    "        for k, v in count.items():\n",
    "            if v > cutoff:\n",
    "                vocab[k] = len(vocab)\n",
    "        return vocab\n",
    "    \n",
    "    def lab2id(self, elements, pad=True):\n",
    "        vocab = {}\n",
    "        if pad:\n",
    "            vocab['pad'] = PAD_TOKEN\n",
    "        for elem in elements:\n",
    "                vocab[elem] = len(vocab)\n",
    "        return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8868bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Words: 861\n",
      "# Slots: 129\n",
      "# Intents: 26\n"
     ]
    }
   ],
   "source": [
    "#ATIS\n",
    "ATIS_words = sum([x['utterance'].split() for x in ATIS_train_raw], []) # No set() since we want to compute \n",
    "                                                            # the cutoff\n",
    "ATIS_corpus = ATIS_train_raw + ATIS_dev_raw + ATIS_test_raw # We do not want unk labels, \n",
    "                                        # however this depends on the research purpose\n",
    "ATIS_slots = set(sum([line['slots'].split() for line in ATIS_corpus],[])) # the type of slots\n",
    "ATIS_intents = set([line['intent'] for line in ATIS_corpus]) #all the intent types\n",
    "\n",
    "ATIS_lang = Lang(ATIS_words, ATIS_intents, ATIS_slots, cutoff=0)\n",
    "\n",
    "print('# Words:', len(ATIS_lang.word2id)-2) # we remove pad and unk from the count\n",
    "print('# Slots:', len(ATIS_lang.slot2id)-1)\n",
    "print('# Intents:', len(ATIS_lang.intent2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4150022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Words: 11417\n",
      "# Slots: 72\n",
      "# Intents: 7\n"
     ]
    }
   ],
   "source": [
    "#SNIPS\n",
    "SNIPS_words = sum([x['utterance'].split() for x in SNIPS_train_raw], []) # No set() since we want to compute \n",
    "                                                            # the cutoff\n",
    "SNIPS_corpus = SNIPS_train_raw + SNIPS_dev_raw + SNIPS_test_raw # We do not want unk labels, \n",
    "                                        # however this depends on the research purpose\n",
    "SNIPS_slots = set(sum([line['slots'].split() for line in SNIPS_corpus],[])) # the type of slots\n",
    "SNIPS_intents = set([line['intent'] for line in SNIPS_corpus]) #all the intent types\n",
    "\n",
    "SNIPS_lang = Lang(SNIPS_words, SNIPS_intents, SNIPS_slots, cutoff=0)\n",
    "\n",
    "print('# Words:', len(SNIPS_lang.word2id)-2) # we remove pad and unk from the count\n",
    "print('# Slots:', len(SNIPS_lang.slot2id)-1)\n",
    "print('# Intents:', len(SNIPS_lang.intent2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b7ad5",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e135b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentsAndSlots (data.Dataset):\n",
    "    # Mandatory methods are __init__, __len__ and __getitem__\n",
    "    def __init__(self, dataset, lang, unk='unk'):\n",
    "        self.utterances = []\n",
    "        self.intents = []\n",
    "        self.slots = []\n",
    "        self.unk = unk\n",
    "        \n",
    "        for x in dataset:\n",
    "            self.utterances.append(x['utterance'])\n",
    "            self.slots.append(x['slots'])\n",
    "            self.intents.append(x['intent'])\n",
    "\n",
    "        self.utt_ids = self.mapping_seq(self.utterances, lang.word2id)\n",
    "        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n",
    "        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        utt = torch.Tensor(self.utt_ids[idx])\n",
    "        slots = torch.Tensor(self.slot_ids[idx])\n",
    "        intent = self.intent_ids[idx]\n",
    "        sample = {'utterance': utt, 'slots': slots, 'intent': intent}\n",
    "        return sample\n",
    "    \n",
    "    # Auxiliary methods\n",
    "    \n",
    "    def mapping_lab(self, data, mapper):\n",
    "        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n",
    "    \n",
    "    def mapping_seq(self, data, mapper): # Map sequences to number\n",
    "        res = []\n",
    "        for seq in data:\n",
    "            tmp_seq = []\n",
    "            for x in seq.split():\n",
    "                if x in mapper:\n",
    "                    tmp_seq.append(mapper[x])\n",
    "                else:\n",
    "                    tmp_seq.append(mapper[self.unk])\n",
    "            res.append(tmp_seq)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27c2ed9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATIS_ dataset\n",
    "ATIS_train_dataset = IntentsAndSlots(ATIS_train_raw, ATIS_lang)\n",
    "ATIS_dev_dataset = IntentsAndSlots(ATIS_dev_raw, ATIS_lang)\n",
    "ATIS_test_dataset = IntentsAndSlots(ATIS_test_raw, ATIS_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ae96461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNIPS_ dataset\n",
    "SNIPS_train_dataset = IntentsAndSlots(SNIPS_train_raw, SNIPS_lang)\n",
    "SNIPS_dev_dataset = IntentsAndSlots(SNIPS_dev_raw, SNIPS_lang)\n",
    "SNIPS_test_dataset = IntentsAndSlots(SNIPS_test_raw, SNIPS_lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f8a01",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8173eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    def merge(sequences):\n",
    "        '''\n",
    "        merge from batch * sent_len to batch * max_len \n",
    "        '''\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        max_len = 1 if max(lengths)==0 else max(lengths)\n",
    "        # Pad token is zero in our case\n",
    "        # So we create a matrix full of PAD_TOKEN (i.e. 0) with the shape \n",
    "        # batch_size X maximum length of a sequence\n",
    "        padded_seqs = torch.LongTensor(len(sequences),max_len).fill_(PAD_TOKEN)\n",
    "        for i, seq in enumerate(sequences):\n",
    "            end = lengths[i]\n",
    "            padded_seqs[i, :end] = seq # We copy each sequence into the matrix\n",
    "        # print(padded_seqs)\n",
    "        padded_seqs = padded_seqs.detach()  # We remove these tensors from the computational graph\n",
    "        return padded_seqs, lengths\n",
    "    # Sort data by seq lengths\n",
    "    data.sort(key=lambda x: len(x['utterance']), reverse=True) \n",
    "    new_item = {}\n",
    "    for key in data[0].keys():\n",
    "        new_item[key] = [d[key] for d in data]\n",
    "    # We just need one length for packed pad seq, since len(utt) == len(slots)\n",
    "    src_utt, _ = merge(new_item['utterance'])\n",
    "    y_slots, y_lengths = merge(new_item[\"slots\"])\n",
    "    intent = torch.LongTensor(new_item[\"intent\"])\n",
    "    \n",
    "    src_utt = src_utt.to(device) # We load the Tensor on our seleceted device\n",
    "    y_slots = y_slots.to(device)\n",
    "    intent = intent.to(device)\n",
    "    y_lengths = torch.LongTensor(y_lengths).to(device)\n",
    "    \n",
    "    new_item[\"utterances\"] = src_utt\n",
    "    new_item[\"intents\"] = intent\n",
    "    new_item[\"y_slots\"] = y_slots\n",
    "    new_item[\"slots_len\"] = y_lengths\n",
    "    return new_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49afca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATIS_ Dataloader instantiation\n",
    "ATIS_train_loader = DataLoader(ATIS_train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n",
    "ATIS_dev_loader = DataLoader(ATIS_dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "ATIS_test_loader = DataLoader(ATIS_test_dataset, batch_size=64, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faf30aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SNIPS_ Dataloader instantiation\n",
    "SNIPS_train_loader = DataLoader(SNIPS_train_dataset, batch_size=128, collate_fn=collate_fn,  shuffle=True)\n",
    "SNIPS_dev_loader = DataLoader(SNIPS_dev_dataset, batch_size=64, collate_fn=collate_fn)\n",
    "SNIPS_test_loader = DataLoader(SNIPS_test_dataset, batch_size=64, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c3b3a5",
   "metadata": {},
   "source": [
    "### Weight initialization\n",
    "\n",
    "Function to randomly initialize the weights of Neural Networks in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd82682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(mat):\n",
    "    for m in mat.modules():\n",
    "        if type(m) in [nn.GRU, nn.LSTM, nn.RNN]:\n",
    "            for name, param in m.named_parameters():\n",
    "                if 'weight_ih' in name:\n",
    "                    for idx in range(4):\n",
    "                        mul = param.shape[0]//4\n",
    "                        torch.nn.init.xavier_uniform_(param[idx*mul:(idx+1)*mul])\n",
    "                elif 'weight_hh' in name:\n",
    "                    for idx in range(4):\n",
    "                        mul = param.shape[0]//4\n",
    "                        torch.nn.init.orthogonal_(param[idx*mul:(idx+1)*mul])\n",
    "                elif 'bias' in name:\n",
    "                    param.data.fill_(0)\n",
    "        else:\n",
    "            if type(m) in [nn.Linear]:\n",
    "                torch.nn.init.uniform_(m.weight, -0.01, 0.01)\n",
    "                if m.bias != None:\n",
    "                    m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1623406",
   "metadata": {},
   "source": [
    "### Evaluation Loop, Predict and Loss analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cbb099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(data, criterion_slots, criterion_intents, model, lang):\n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    ref_slots = []\n",
    "    hyp_slots = []\n",
    "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
    "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
    "        for sample in data:\n",
    "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
    "            loss_intent = criterion_intents(intents, sample['intents'])\n",
    "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "            loss = loss_intent + loss_slot \n",
    "            loss_array.append(loss.item())\n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            # Slot inference \n",
    "            output_slots = torch.argmax(slots, dim=1)\n",
    "            for id_seq, seq in enumerate(output_slots):\n",
    "                length = sample['slots_len'].tolist()[id_seq]\n",
    "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
    "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
    "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
    "                to_decode = seq[:length].tolist()\n",
    "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
    "                tmp_seq = []\n",
    "                for id_el, elem in enumerate(to_decode):\n",
    "                    #tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n",
    "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]) if elem != 0 else (utterance[id_el], 'O'))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:\n",
    "        results = evaluate(ref_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predics a class that is not in REF\n",
    "        print(ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        \n",
    "    report_intent = classification_report(ref_intents, hyp_intents, \n",
    "                                          zero_division=False, output_dict=True)\n",
    "    return results, report_intent, loss_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d9ce7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, criterion_slots, criterion_intents, model, lang):\n",
    "    model.eval()\n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    ref_slots = []\n",
    "    hyp_slots = []\n",
    "    #softmax = nn.Softmax(dim=1) # Use Softmax if you need the actual probability\n",
    "    with torch.no_grad(): # It used to avoid the creation of computational graph\n",
    "        for sample in data:\n",
    "            slots, intents = model(sample['utterances'], sample['slots_len'])\n",
    "            loss_intent = criterion_intents(intents, sample['intents'])\n",
    "            loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "            loss = loss_intent + loss_slot \n",
    "            loss_array.append(loss.item())\n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intents'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            # Slot inference \n",
    "            output_slots = torch.argmax(slots, dim=1)\n",
    "            for id_seq, seq in enumerate(output_slots):\n",
    "                length = sample['slots_len'].tolist()[id_seq]\n",
    "                utt_ids = sample['utterance'][id_seq][:length].tolist()\n",
    "                gt_ids = sample['y_slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids[:length]]\n",
    "                utterance = [lang.id2word[elem] for elem in utt_ids]\n",
    "                to_decode = seq[:length].tolist()\n",
    "                ref_slots.append([(utterance[id_el], elem) for id_el, elem in enumerate(gt_slots)])\n",
    "                tmp_seq = []\n",
    "                for id_el, elem in enumerate(to_decode):\n",
    "                    tmp_seq.append((utterance[id_el], lang.id2slot[elem]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:            \n",
    "        results = evaluate(ref_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predics a class that is not in REF\n",
    "        print(ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        \n",
    "    return hyp_intents,ref_intents,hyp_slots,ref_slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f67a7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(sampled_epochs, loss_train, loss_dev):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title('Training Losses')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(sampled_epochs, loss_train, label='Train loss')\n",
    "    plt.plot(sampled_epochs, loss_dev, label='Dev loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e37b78",
   "metadata": {},
   "source": [
    "### Error Analysis Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "058ca47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_accuracy(pred,gt):\n",
    "    lenght=len(pred)\n",
    "    correct=0\n",
    "    for i in range(0,lenght):\n",
    "        if(pred[i]==gt[i]):\n",
    "            correct+=1\n",
    "    return correct/lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f29f5f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intent accuracy by sentence lenght, provides bar plot with intent accuracy per sentence lenght, useful to detect potential deficits in long sentences\n",
    "def intent_acc_lenght(intent_hyp,intent_gt, ATIS=True):\n",
    "    dataset=\"\"\n",
    "    if(ATIS):\n",
    "        dataset=\"ATIS\"\n",
    "    else:\n",
    "        dataset=\"SNIPS\"\n",
    "    test_results=[]\n",
    "    for i in range(0,50):\n",
    "        test_results.append([])\n",
    "    for i in range(0,len(intent_hyp)):\n",
    "        sent_lenght=len(slot_gt[i])\n",
    "        #print(sent_lenght)\n",
    "        test_results[sent_lenght].append((intent_hyp[i],intent_gt[i]))\n",
    "\n",
    "    #Measure accuracy at each sentence lenght\n",
    "    pred=[]\n",
    "    true=[]\n",
    "    sent_length=[]\n",
    "    accuracy_values=[]\n",
    "    accuracy_lenght=[]\n",
    "    for index in range(0,50):\n",
    "        if(len(test_results[index])!=0):\n",
    "            for (hyp, gt) in test_results[index]:\n",
    "                pred.append(hyp)\n",
    "                true.append(gt)\n",
    "            print(\"Accuracy at sentence lenght \",index,\"=\",intent_accuracy(pred, true))\n",
    "            sent_length.append(index)\n",
    "            accuracy_values.append(intent_accuracy(pred, true))\n",
    "\n",
    "    #Plot results\n",
    "    print(\"=\"*85)\n",
    "    print(dataset,\" Intent Accuracy by sentence length\")\n",
    "    plt.xticks(sent_length)\n",
    "\n",
    "    plt.bar(sent_length,accuracy_values,width=0.8)\n",
    "    plt.show()\n",
    "    #Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ca504544",
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_keys=['accuracy', 'macro avg', 'weighted avg','total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea4e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intent_confusion_matrix():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8c6a9560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intents_accuracy(intents_test):\n",
    "    intents={}\n",
    "    for intent in intents_test.items():\n",
    "        name,dict_value=intent\n",
    "        if(name not in discard_keys):\n",
    "            intents[name]=dict_value['f1-score']\n",
    "    best_intents=sorted(intents.items(), key=lambda x: x[1], reverse=True)\n",
    "    worst_intents=sorted(intents.items(), key=lambda x: x[1])\n",
    "    return best_intents,worst_intents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "480e34ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slots_f1(slots_test):\n",
    "    slots={}\n",
    "    for slot in slots_test.items():\n",
    "        name,dict_value=slot\n",
    "        if(name not in discard_keys):\n",
    "            slots[name]=dict_value['f']\n",
    "    best_slots=sorted(slots.items(), key=lambda x: x[1], reverse=True)\n",
    "    worst_slots=sorted(slots.items(), key=lambda x: x[1])\n",
    "    return best_slots,worst_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844d23c",
   "metadata": {},
   "source": [
    "# 2) Baseline Model\n",
    "\n",
    "As a baseline model i took the Neural Network that was presented during lab experience #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "560cad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelIAS(nn.Module):\n",
    "\n",
    "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=1, pad_index=0):\n",
    "        super(ModelIAS, self).__init__()\n",
    "        # hid_size = Hidden size\n",
    "        # out_slot = number of slots (output size for slot filling)\n",
    "        # out_int = number of intents (ouput size for intent class)\n",
    "        # emb_size = word embedding size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n",
    "        \n",
    "        self.utt_encoder = nn.LSTM(emb_size, hid_size, n_layer, bidirectional=False)    \n",
    "        self.slot_out = nn.Linear(hid_size, out_slot)\n",
    "        self.intent_out = nn.Linear(hid_size, out_int)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def forward(self, utterance, seq_lengths):\n",
    "        # utterance.size() = batch_size X seq_len\n",
    "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
    "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
    "        \n",
    "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
    "        \n",
    "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
    "        # Process the batch\n",
    "        packed_output, (last_hidden, cell) = self.utt_encoder(packed_input) \n",
    "        # Unpack the sequence\n",
    "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
    "        # Get the last hidden state\n",
    "        last_hidden = last_hidden[-1,:,:]\n",
    "        # Compute slot logits\n",
    "        slots = self.slot_out(utt_encoded)\n",
    "        # Compute intent logits\n",
    "        intent = self.intent_out(last_hidden)\n",
    "        \n",
    "        # Slot size: seq_len, batch size, calsses \n",
    "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
    "        # Slot size: batch_size, classes, seq_len\n",
    "        return slots, intent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee891591",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5bf7c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 200\n",
    "emb_size = 300\n",
    "\n",
    "lr = 0.0001 # learning rate\n",
    "clip = 5 # Clip the gradient\n",
    "\n",
    "ATIS_out_slot = len(ATIS_lang.slot2id)\n",
    "ATIS_out_int = len(ATIS_lang.intent2id)\n",
    "ATIS_vocab_len = len(ATIS_lang.word2id)\n",
    "\n",
    "SNIPS_out_slot = len(SNIPS_lang.slot2id)\n",
    "SNIPS_out_int = len(SNIPS_lang.intent2id)\n",
    "SNIPS_vocab_len = len(SNIPS_lang.word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690959ae",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a00ab76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(data, optimizer, criterion_slots, criterion_intents, model):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for sample in data:\n",
    "        optimizer.zero_grad() # Zeroing the gradient\n",
    "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
    "        loss_intent = criterion_intents(intent, sample['intents'])\n",
    "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "        loss = loss_intent + loss_slot # In joint training we sum the losses. \n",
    "                                       # Is there another way to do that?\n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward() # Compute the gradient, deleting the computational graph\n",
    "        # clip the gradient to avoid explosioning gradients\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
    "        optimizer.step() # Update the weights\n",
    "    return loss_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0174c",
   "metadata": {},
   "source": [
    "### Training procedure\n",
    "\n",
    "Multiple runs are made to compute accuracy and f1 mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "881fa718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:19<00:00, 63.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slot F1 0.92 +- 0.004\n",
      "Intent Acc 0.931 +- 0.004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ATIS\n",
    "n_epochs = 200\n",
    "early_stopping=3\n",
    "patience = early_stopping\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "\n",
    "runs = 5\n",
    "ATIS_slot_f1s, ATIS_intent_acc = [], []\n",
    "for x in tqdm(range(0, runs)):\n",
    "    ATIS_model = ModelIAS(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "    ATIS_model.apply(init_weights)\n",
    "    \n",
    "    ATIS_optimizer = optim.Adam(ATIS_model.parameters(), lr=lr)\n",
    "    ATIS_criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "    ATIS_criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token\n",
    "    \n",
    "    n_epochs = 200\n",
    "    early_stopping=3\n",
    "    patience = early_stopping\n",
    "    losses_train = []\n",
    "    losses_dev = []\n",
    "    sampled_epochs = []\n",
    "    best_f1 = 0\n",
    "\n",
    "    for x in range(1,n_epochs):\n",
    "        \n",
    "        loss = train_loop(ATIS_train_loader, ATIS_optimizer, ATIS_criterion_slots, \n",
    "                      ATIS_criterion_intents, ATIS_model)\n",
    "        if x % 5 == 0:\n",
    "            sampled_epochs.append(x)\n",
    "            losses_train.append(np.asarray(loss).mean())\n",
    "            results_dev=\"\"\n",
    "            results_dev, intent_res, loss_dev = eval_loop(ATIS_dev_loader, ATIS_criterion_slots, \n",
    "                                                          ATIS_criterion_intents, ATIS_model, ATIS_lang)\n",
    "            losses_dev.append(np.asarray(loss_dev).mean())\n",
    "            f1 = results_dev['total']['f']\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience <= 0: # Early stoping with patient\n",
    "                break # Not nice but it keeps the code clean\n",
    "\n",
    "    ATIS_results_test, ATIS_intent_test, _ = eval_loop(ATIS_test_loader, ATIS_criterion_slots, \n",
    "                                         ATIS_criterion_intents, ATIS_model, ATIS_lang)\n",
    "    ATIS_intent_acc.append(ATIS_intent_test['accuracy'])\n",
    "    ATIS_slot_f1s.append(ATIS_results_test['total']['f'])\n",
    "\n",
    "\n",
    "\n",
    "ATIS_slot_f1s = np.asarray(ATIS_slot_f1s)\n",
    "ATIS_intent_acc = np.asarray(ATIS_intent_acc)\n",
    "print('Slot F1', round(ATIS_slot_f1s.mean(),3), '+-', round(ATIS_slot_f1s.std(),3))\n",
    "print('Intent Acc', round(ATIS_intent_acc.mean(), 3), '+-', round(ATIS_slot_f1s.std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83653410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [07:42<00:00, 92.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slot F1 0.791 +- 0.009\n",
      "Intent Acc 0.96 +- 0.009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#SNIPS\n",
    "n_epochs = 200\n",
    "early_stopping=3\n",
    "patience = early_stopping\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "\n",
    "runs = 5\n",
    "SNIPS_slot_f1s, SNIPS_intent_acc = [], []\n",
    "for x in tqdm(range(0, runs)):\n",
    "    SNIPS_model = ModelIAS(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "    SNIPS_model.apply(init_weights)\n",
    "    \n",
    "    SNIPS_optimizer = optim.Adam(SNIPS_model.parameters(), lr=lr)\n",
    "    SNIPS_criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "    SNIPS_criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token\n",
    "    \n",
    "    n_epochs = 200\n",
    "    early_stopping=3\n",
    "    patience = early_stopping\n",
    "    losses_train = []\n",
    "    losses_dev = []\n",
    "    sampled_epochs = []\n",
    "    best_f1 = 0\n",
    "\n",
    "    for x in range(1,n_epochs):\n",
    "        \n",
    "        loss = train_loop(SNIPS_train_loader, SNIPS_optimizer, SNIPS_criterion_slots, \n",
    "                      SNIPS_criterion_intents, SNIPS_model)\n",
    "        if x % 5 == 0:\n",
    "            sampled_epochs.append(x)\n",
    "            losses_train.append(np.asarray(loss).mean())\n",
    "            results_dev, intent_res, loss_dev = eval_loop(SNIPS_dev_loader, SNIPS_criterion_slots, \n",
    "                                                          SNIPS_criterion_intents, SNIPS_model, SNIPS_lang)\n",
    "            losses_dev.append(np.asarray(loss_dev).mean())\n",
    "            f1 = results_dev['total']['f']\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience <= 0: # Early stoping with patient\n",
    "                break # Not nice but it keeps the code clean\n",
    "\n",
    "    SNIPS_results_test, SNIPS_intent_test, _ = eval_loop(SNIPS_test_loader, SNIPS_criterion_slots, \n",
    "                                         SNIPS_criterion_intents, SNIPS_model, SNIPS_lang)\n",
    "    SNIPS_intent_acc.append(SNIPS_intent_test['accuracy'])\n",
    "    SNIPS_slot_f1s.append(SNIPS_results_test['total']['f'])\n",
    "\n",
    "\n",
    "\n",
    "SNIPS_slot_f1s = np.asarray(SNIPS_slot_f1s)\n",
    "SNIPS_intent_acc = np.asarray(SNIPS_intent_acc)\n",
    "print('Slot F1', round(SNIPS_slot_f1s.mean(),3), '+-', round(SNIPS_slot_f1s.std(),3))\n",
    "print('Intent Acc', round(SNIPS_intent_acc.mean(), 3), '+-', round(SNIPS_slot_f1s.std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1f4ef905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['service', 'party_size_description', 'object_type', 'track', 'album', 'poi', 'spatial_relation', 'playlist_owner', 'location_name', 'condition_description', 'music_item', 'city', 'geographic_poi', 'object_select', 'facility', 'party_size_number', 'current_location', 'year', 'rating_unit', 'object_part_of_series_type', 'playlist', 'genre', 'entity_name', 'object_name', 'movie_type', 'movie_name', 'state', 'artist', 'object_location_type', 'cuisine', 'served_dish', 'best_rating', 'sort', 'condition_temperature', 'rating_value', 'timeRange', 'restaurant_type', 'restaurant_name', 'country', 'total'])\n",
      "{'p': 0.7625641025641026, 'r': 0.8307262569832402, 'f': 0.795187165775401, 's': 1790}\n"
     ]
    }
   ],
   "source": [
    "print(SNIPS_results_test.keys())\n",
    "print(SNIPS_results_test['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0147e644",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687eea6",
   "metadata": {},
   "source": [
    "### Labels classification performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee71b37",
   "metadata": {},
   "source": [
    "#### ATIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "933542c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flight_time</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>0.985075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capacity</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight</td>\n",
       "      <td>0.974279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airline</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airport</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ground_service</td>\n",
       "      <td>0.921053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airfare</td>\n",
       "      <td>0.893204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ground_fare</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>distance</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Intent     Score\n",
       "0     flight_time  1.000000\n",
       "1    abbreviation  0.985075\n",
       "2        capacity  0.975610\n",
       "3          flight  0.974279\n",
       "4         airline  0.950000\n",
       "5         airport  0.941176\n",
       "6  ground_service  0.921053\n",
       "7         airfare  0.893204\n",
       "8     ground_fare  0.833333\n",
       "9        distance  0.800000"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Best scoring intents\")\n",
    "\n",
    "best,worst=intents_accuracy(ATIS_intent_test)\n",
    "\n",
    "df = pd.DataFrame(best[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2120778f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airfare+flight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day_name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight+airline</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flight_no</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flight_no+airline</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meal</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flight+airfare</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aircraft</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Intent     Score\n",
       "0     airfare+flight  0.000000\n",
       "1               city  0.000000\n",
       "2           day_name  0.000000\n",
       "3     flight+airline  0.000000\n",
       "4          flight_no  0.000000\n",
       "5  flight_no+airline  0.000000\n",
       "6               meal  0.000000\n",
       "7     flight+airfare  0.142857\n",
       "8           quantity  0.500000\n",
       "9           aircraft  0.800000"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring intents\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4ebac683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fromloc.airport_code</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flight_stop</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>connect</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight_days</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flight_time</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fromloc.state_code</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>toloc.country_name</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>toloc.state_code</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>economy</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>state_code</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Slot  Score\n",
       "0  fromloc.airport_code    1.0\n",
       "1           flight_stop    1.0\n",
       "2               connect    1.0\n",
       "3           flight_days    1.0\n",
       "4           flight_time    1.0\n",
       "5    fromloc.state_code    1.0\n",
       "6    toloc.country_name    1.0\n",
       "7      toloc.state_code    1.0\n",
       "8               economy    1.0\n",
       "9            state_code    1.0"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best,worst=slots_f1(ATIS_results_test)\n",
    "\n",
    "print(\"10 Best scoring slots\")\n",
    "df = pd.DataFrame(best[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3cb65280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>return_date.day_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>compartment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meal_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>return_date.date_relative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>airport_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>stoploc.airport_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fare_amount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mod</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Slot  Score\n",
       "0                 state_name    0.0\n",
       "1       return_date.day_name    0.0\n",
       "2                compartment    0.0\n",
       "3                     flight    0.0\n",
       "4                  meal_code    0.0\n",
       "5  return_date.date_relative    0.0\n",
       "6               airport_code    0.0\n",
       "7       stoploc.airport_code    0.0\n",
       "8                fare_amount    0.0\n",
       "9                        mod    0.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring slots\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bece7a",
   "metadata": {},
   "source": [
    "#### SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d0f24134",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>0.993789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>0.983784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GetWeather</td>\n",
       "      <td>0.976077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>0.955056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>0.946860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Intent     Score\n",
       "0         AddToPlaylist  1.000000\n",
       "1              RateBook  0.993789\n",
       "2        BookRestaurant  0.983784\n",
       "3            GetWeather  0.976077\n",
       "4             PlayMusic  0.955056\n",
       "5  SearchScreeningEvent  0.946860\n",
       "6    SearchCreativeWork  0.924528"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Best scoring intents\")\n",
    "\n",
    "best,worst=intents_accuracy(SNIPS_intent_test)\n",
    "\n",
    "df = pd.DataFrame(best[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9bcab7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>0.924528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>0.946860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>0.955056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GetWeather</td>\n",
       "      <td>0.976077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>0.983784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>0.993789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Intent     Score\n",
       "0    SearchCreativeWork  0.924528\n",
       "1  SearchScreeningEvent  0.946860\n",
       "2             PlayMusic  0.955056\n",
       "3            GetWeather  0.976077\n",
       "4        BookRestaurant  0.983784\n",
       "5              RateBook  0.993789\n",
       "6         AddToPlaylist  1.000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring intents\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7b036c90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facility</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rating_unit</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie_type</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best_rating</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rating_value</td>\n",
       "      <td>0.987500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>condition_temperature</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>music_item</td>\n",
       "      <td>0.966825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>current_location</td>\n",
       "      <td>0.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>party_size_number</td>\n",
       "      <td>0.961538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sort</td>\n",
       "      <td>0.955224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Slot     Score\n",
       "0               facility  1.000000\n",
       "1            rating_unit  1.000000\n",
       "2             movie_type  1.000000\n",
       "3            best_rating  1.000000\n",
       "4           rating_value  0.987500\n",
       "5  condition_temperature  0.977778\n",
       "6             music_item  0.966825\n",
       "7       current_location  0.962963\n",
       "8      party_size_number  0.961538\n",
       "9                   sort  0.955224"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best,worst=slots_f1(SNIPS_results_test)\n",
    "\n",
    "print(\"10 Best scoring slots\")\n",
    "df = pd.DataFrame(best[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3229be1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geographic_poi</td>\n",
       "      <td>0.121212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>city</td>\n",
       "      <td>0.277228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entity_name</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>album</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>country</td>\n",
       "      <td>0.452055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>object_name</td>\n",
       "      <td>0.543750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>party_size_description</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>movie_name</td>\n",
       "      <td>0.585859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>poi</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Slot     Score\n",
       "0          geographic_poi  0.121212\n",
       "1                   track  0.272727\n",
       "2                    city  0.277228\n",
       "3             entity_name  0.333333\n",
       "4                   album  0.380952\n",
       "5                 country  0.452055\n",
       "6             object_name  0.543750\n",
       "7  party_size_description  0.583333\n",
       "8              movie_name  0.585859\n",
       "9                     poi  0.588235"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring slots\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be66f7f",
   "metadata": {},
   "source": [
    "### Intent Detection Accuracy by Utterance length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efccd12",
   "metadata": {},
   "source": [
    "#### ATIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d0c4ca37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at sentence lenght  2 = 0.5\n",
      "Accuracy at sentence lenght  3 = 0.8181818181818182\n",
      "Accuracy at sentence lenght  4 = 0.9534883720930233\n",
      "Accuracy at sentence lenght  5 = 0.9743589743589743\n",
      "Accuracy at sentence lenght  6 = 0.9323308270676691\n",
      "Accuracy at sentence lenght  7 = 0.9323671497584541\n",
      "Accuracy at sentence lenght  8 = 0.9415584415584416\n",
      "Accuracy at sentence lenght  9 = 0.9478672985781991\n",
      "Accuracy at sentence lenght  10 = 0.9571150097465887\n",
      "Accuracy at sentence lenght  11 = 0.955\n",
      "Accuracy at sentence lenght  12 = 0.9523099850968704\n",
      "Accuracy at sentence lenght  13 = 0.951856946354883\n",
      "Accuracy at sentence lenght  14 = 0.9468223086900129\n",
      "Accuracy at sentence lenght  15 = 0.9422835633626098\n",
      "Accuracy at sentence lenght  16 = 0.9425149700598803\n",
      "Accuracy at sentence lenght  17 = 0.9407665505226481\n",
      "Accuracy at sentence lenght  18 = 0.9398843930635838\n",
      "Accuracy at sentence lenght  19 = 0.9402298850574713\n",
      "Accuracy at sentence lenght  20 = 0.9383561643835616\n",
      "Accuracy at sentence lenght  21 = 0.9367945823927766\n",
      "Accuracy at sentence lenght  22 = 0.9369369369369369\n",
      "Accuracy at sentence lenght  23 = 0.937007874015748\n",
      "Accuracy at sentence lenght  29 = 0.9372197309417041\n",
      "Accuracy at sentence lenght  30 = 0.9372900335946248\n",
      "=====================================================================================\n",
      "ATIS  Intent Accuracy by sentence length\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intent_hyp,intent_gt,slot_hyp,slot_gt=predict(ATIS_test_loader, ATIS_criterion_slots,\n",
    "                                              ATIS_criterion_intents, ATIS_model, ATIS_lang)\n",
    "#Slot is array of array, intent is array of strings\n",
    "\n",
    "#Get an array of (predictions,ground truth) based on utterance length\n",
    "intent_acc_lenght(intent_hyp,intent_gt, ATIS=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72732ef",
   "metadata": {},
   "source": [
    "#### SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "119df065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at sentence lenght  3 = 0.8888888888888888\n",
      "Accuracy at sentence lenght  4 = 0.9142857142857143\n",
      "Accuracy at sentence lenght  5 = 0.9518072289156626\n",
      "Accuracy at sentence lenght  6 = 0.9503105590062112\n",
      "Accuracy at sentence lenght  7 = 0.9612403100775194\n",
      "Accuracy at sentence lenght  8 = 0.9567723342939481\n",
      "Accuracy at sentence lenght  9 = 0.9647887323943662\n",
      "Accuracy at sentence lenght  10 = 0.9691991786447639\n",
      "Accuracy at sentence lenght  11 = 0.9656419529837251\n",
      "Accuracy at sentence lenght  12 = 0.9679595278246206\n",
      "Accuracy at sentence lenght  13 = 0.9665071770334929\n",
      "Accuracy at sentence lenght  14 = 0.9662058371735791\n",
      "Accuracy at sentence lenght  15 = 0.9669669669669669\n",
      "Accuracy at sentence lenght  16 = 0.967741935483871\n",
      "Accuracy at sentence lenght  17 = 0.9680696661828737\n",
      "Accuracy at sentence lenght  18 = 0.9682080924855492\n",
      "Accuracy at sentence lenght  19 = 0.968299711815562\n",
      "Accuracy at sentence lenght  20 = 0.9684361549497847\n",
      "Accuracy at sentence lenght  21 = 0.9684813753581661\n",
      "Accuracy at sentence lenght  22 = 0.9685264663805436\n",
      "Accuracy at sentence lenght  24 = 0.9685714285714285\n",
      "=====================================================================================\n",
      "SNIPS  Intent Accuracy by sentence length\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "intent_hyp,intent_gt,slot_hyp,slot_gt=predict(SNIPS_test_loader, SNIPS_criterion_slots,\n",
    "                                              SNIPS_criterion_intents, SNIPS_model, SNIPS_lang)\n",
    "#Slot is array of array, intent is array of strings\n",
    "#Get an array of (predictions,ground truth) based on utterance length\n",
    "intent_acc_lenght(intent_hyp,intent_gt, ATIS=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0087c2",
   "metadata": {},
   "source": [
    "# 3) Second Model - Bi-Directional Encoder with GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb44b74",
   "metadata": {},
   "source": [
    "The idea of this second model is to take the architecture of the baseline and apply improvements.\n",
    "The overall structure is still the same, with a joint encoder used for both Slot-Filling and Intent-Detection task and apply two separate classifiers at the end, one for each task.\n",
    "\n",
    "However, the 1-layer, monodirectional LSTM has been replaced by a bi-directional 2 layer GRU.\n",
    "The structure of the GRU implies a reduction in trainable parameters compared to LSTM, speeding up the training process and reducing the risk of overfitting.\n",
    "\n",
    "Thanks to the speeding up in training time, a layer was added to the encoder that resulted in an increase in accuracy.\n",
    "Deeper architecture with more layers were tried but were much slower in training and did not produce improvements during the evaluation compared to the 2 layer model.\n",
    "\n",
    "Also, a change in the loss computation is made:\n",
    "\n",
    "$Loss= \\alpha * Loss_i + \\beta * Loss_s$\n",
    "\n",
    "where:\n",
    "\n",
    "- $Loss_i$ is the intent detection task loss \n",
    "- $Loss_s$ is slot filling task loss\n",
    "- $\\alpha + \\beta = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7069301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGRU(nn.Module):\n",
    "    def __init__(self, hid_size, out_slot, out_int, emb_size, vocab_len, n_layer=2, pad_index=0):\n",
    "        super(BiGRU, self).__init__()\n",
    "        # hid_size = Hidden size\n",
    "        # out_slot = number of slots (output size for slot filling)\n",
    "        # out_int = number of intents (ouput size for intent class)\n",
    "        # emb_size = word embedding size\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_len, emb_size, padding_idx=pad_index)\n",
    "        \n",
    "        self.utt_encoder = nn.GRU(emb_size, hid_size, n_layer,dropout=0.4, bidirectional=True)    \n",
    "        self.slot_out = nn.Linear(hid_size*2, out_slot)\n",
    "        self.intent_out = nn.Linear(hid_size, out_int)\n",
    "        self.dropout = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, utterance, seq_lengths):\n",
    "        # utterance.size() = batch_size X seq_len\n",
    "        utt_emb = self.embedding(utterance) # utt_emb.size() = batch_size X seq_len X emb_size\n",
    "        utt_emb = utt_emb.permute(1,0,2) # we need seq len first -> seq_len X batch_size X emb_size\n",
    "        \n",
    "        # pack_padded_sequence avoid computation over pad tokens reducing the computational cost\n",
    "        \n",
    "        packed_input = pack_padded_sequence(utt_emb, seq_lengths.cpu().numpy())\n",
    "        # Process the batch\n",
    "        packed_output, last_hidden = self.utt_encoder(packed_input) \n",
    "        \n",
    "        # Unpack the sequence\n",
    "        utt_encoded, input_sizes = pad_packed_sequence(packed_output)\n",
    "        # Get the last hidden state\n",
    "        last_hidden = last_hidden[-1,:,:]\n",
    "        \n",
    "        \n",
    "        # Compute slot logits\n",
    "        slots = self.slot_out(utt_encoded)\n",
    "        # Compute intent logits\n",
    "        intent = self.intent_out(last_hidden)\n",
    "        \n",
    "        # Slot size: seq_len, batch size, calsses \n",
    "        slots = slots.permute(1,2,0) # We need this for computing the loss\n",
    "        # Slot size: batch_size, classes, seq_len\n",
    "        return slots, intent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb2fe1",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5bac01fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hid_size = 200\n",
    "emb_size = 300\n",
    "\n",
    "lr = 0.0005 # learning rate\n",
    "clip = 5 # Clip the gradient\n",
    "\n",
    "ATIS_out_slot = len(ATIS_lang.slot2id)\n",
    "ATIS_out_int = len(ATIS_lang.intent2id)\n",
    "ATIS_vocab_len = len(ATIS_lang.word2id)\n",
    "\n",
    "SNIPS_out_slot = len(SNIPS_lang.slot2id)\n",
    "SNIPS_out_int = len(SNIPS_lang.intent2id)\n",
    "SNIPS_vocab_len = len(SNIPS_lang.word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200fe00",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d2bf062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_bigru(data, optimizer, criterion_slots, criterion_intents, model):\n",
    "    model.train()\n",
    "    loss_array = []\n",
    "    for sample in data:\n",
    "        optimizer.zero_grad() # Zeroing the gradient\n",
    "        slots, intent = model(sample['utterances'], sample['slots_len'])\n",
    "        loss_intent = criterion_intents(intent, sample['intents'])\n",
    "        loss_slot = criterion_slots(slots, sample['y_slots'])\n",
    "        \n",
    "        alpha=random.uniform(0, 1)\n",
    "        beta=1-alpha\n",
    "        \n",
    "        #alpha=0.3\n",
    "        #beta=0.7\n",
    "        \n",
    "        loss=max(alpha,beta) * loss_slot + min(alpha,beta) * loss_intent\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward() # Compute the gradient, deleting the computational graph\n",
    "        # clip the gradient to avoid explosioning gradients\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  \n",
    "        optimizer.step() # Update the weights\n",
    "    return loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c079dcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [03:04<00:00, 36.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATIS\n",
      "Slot F1 0.949 +- 0.001\n",
      "Intent Acc 0.957 +- 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ATIS\n",
    "n_epochs = 200\n",
    "early_stopping=3\n",
    "patience = early_stopping\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "\n",
    "runs = 5\n",
    "slot_f1s, intent_acc = [], []\n",
    "for x in tqdm(range(0, runs)):\n",
    "    ATIS_bigru = BiGRU(hid_size, ATIS_out_slot, ATIS_out_int, emb_size, ATIS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "    ATIS_bigru.apply(init_weights)\n",
    "    \n",
    "    ATIS_optimizer = optim.Adam(ATIS_bigru.parameters(), lr=lr)\n",
    "    ATIS_criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "    ATIS_criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token\n",
    "    \n",
    "    n_epochs = 200\n",
    "    early_stopping=3\n",
    "    patience = early_stopping\n",
    "    losses_train = []\n",
    "    losses_dev = []\n",
    "    sampled_epochs = []\n",
    "    best_f1 = 0\n",
    "\n",
    "    for x in range(1,n_epochs):\n",
    "        \n",
    "        loss = train_loop_bigru(ATIS_train_loader, ATIS_optimizer, ATIS_criterion_slots, \n",
    "                      ATIS_criterion_intents, ATIS_bigru)\n",
    "        if x % 5 == 0:\n",
    "            sampled_epochs.append(x)\n",
    "            losses_train.append(np.asarray(loss).mean())\n",
    "            results_dev=\"\"\n",
    "            results_dev, intent_res, loss_dev = eval_loop(ATIS_dev_loader, ATIS_criterion_slots, \n",
    "                                                          ATIS_criterion_intents, ATIS_bigru, ATIS_lang)\n",
    "            losses_dev.append(np.asarray(loss_dev).mean())\n",
    "            f1 = results_dev['total']['f']\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience <= 0: # Early stoping with patient\n",
    "                break # Not nice but it keeps the code clean\n",
    "\n",
    "    ATIS_results_test, ATIS_intent_test, _ = eval_loop(ATIS_test_loader, ATIS_criterion_slots, \n",
    "                                         ATIS_criterion_intents, ATIS_bigru, ATIS_lang)\n",
    "    intent_acc.append(ATIS_intent_test['accuracy'])\n",
    "    slot_f1s.append(ATIS_results_test['total']['f'])\n",
    "\n",
    "\n",
    "\n",
    "slot_f1s = np.asarray(slot_f1s)\n",
    "intent_acc = np.asarray(intent_acc)\n",
    "print(\"ATIS\")\n",
    "print('Slot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
    "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ea956ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [05:10<00:00, 62.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNIPS\n",
      "Slot F1 0.9 +- 0.006\n",
      "Intent Acc 0.97 +- 0.006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#SNIPS\n",
    "n_epochs = 200\n",
    "early_stopping=3\n",
    "patience = early_stopping\n",
    "losses_train = []\n",
    "losses_dev = []\n",
    "sampled_epochs = []\n",
    "best_f1 = 0\n",
    "\n",
    "runs = 5\n",
    "slot_f1s, intent_acc = [], []\n",
    "for x in tqdm(range(0, runs)):\n",
    "    SNIPS_bigru = BiGRU(hid_size, SNIPS_out_slot, SNIPS_out_int, emb_size, SNIPS_vocab_len, pad_index=PAD_TOKEN).to(device)\n",
    "    SNIPS_bigru.apply(init_weights)\n",
    "    \n",
    "    SNIPS_optimizer = optim.Adam(SNIPS_bigru.parameters(), lr=lr)\n",
    "    SNIPS_criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "    SNIPS_criterion_intents = nn.CrossEntropyLoss() # Because we do not have the pad token\n",
    "    \n",
    "    n_epochs = 200\n",
    "    early_stopping=3\n",
    "    patience = early_stopping\n",
    "    losses_train = []\n",
    "    losses_dev = []\n",
    "    sampled_epochs = []\n",
    "    best_f1 = 0\n",
    "\n",
    "    for x in range(1,n_epochs):\n",
    "        \n",
    "        loss = train_loop_bigru(SNIPS_train_loader, SNIPS_optimizer, SNIPS_criterion_slots, \n",
    "                      SNIPS_criterion_intents, SNIPS_bigru)\n",
    "        if x % 5 == 0:\n",
    "            sampled_epochs.append(x)\n",
    "            losses_train.append(np.asarray(loss).mean())\n",
    "            results_dev=\"\"\n",
    "            results_dev, intent_res, loss_dev = eval_loop(SNIPS_dev_loader, SNIPS_criterion_slots, \n",
    "                                                          SNIPS_criterion_intents, SNIPS_bigru, SNIPS_lang)\n",
    "            losses_dev.append(np.asarray(loss_dev).mean())\n",
    "            f1 = results_dev['total']['f']\n",
    "\n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "            else:\n",
    "                patience -= 1\n",
    "            if patience <= 0: # Early stoping with patient\n",
    "                break # Not nice but it keeps the code clean\n",
    "\n",
    "    SNIPS_results_test, SNIPS_intent_test, _ = eval_loop(SNIPS_test_loader, SNIPS_criterion_slots, \n",
    "                                         SNIPS_criterion_intents, SNIPS_bigru, SNIPS_lang)\n",
    "    intent_acc.append(SNIPS_intent_test['accuracy'])\n",
    "    slot_f1s.append(SNIPS_results_test['total']['f'])\n",
    "\n",
    "\n",
    "\n",
    "slot_f1s = np.asarray(slot_f1s)\n",
    "intent_acc = np.asarray(intent_acc)\n",
    "print(\"SNIPS\")\n",
    "print('Slot F1', round(slot_f1s.mean(),3), '+-', round(slot_f1s.std(),3))\n",
    "print('Intent Acc', round(intent_acc.mean(), 3), '+-', round(slot_f1s.std(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7270a6",
   "metadata": {},
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf38cb",
   "metadata": {},
   "source": [
    "### Labels classification performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0685a4",
   "metadata": {},
   "source": [
    "#### ATIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b520e0eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flight</td>\n",
       "      <td>0.979688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>airfare</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capacity</td>\n",
       "      <td>0.975610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>airline</td>\n",
       "      <td>0.962025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ground_service</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>distance</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>airport</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flight_no</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ground_fare</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Intent     Score\n",
       "0    abbreviation  1.000000\n",
       "1          flight  0.979688\n",
       "2         airfare  0.979167\n",
       "3        capacity  0.975610\n",
       "4         airline  0.962025\n",
       "5  ground_service  0.960000\n",
       "6        distance  0.947368\n",
       "7         airport  0.882353\n",
       "8       flight_no  0.875000\n",
       "9     ground_fare  0.833333"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Best scoring intents\")\n",
    "\n",
    "best,worst=intents_accuracy(ATIS_intent_test)\n",
    "\n",
    "df = pd.DataFrame(best[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f730af26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airfare+flight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>city</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>day_name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight+airline</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flight_no+airline</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flight_time</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flight+airfare</td>\n",
       "      <td>0.470588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meal</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aircraft</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Intent     Score\n",
       "0     airfare+flight  0.000000\n",
       "1               city  0.000000\n",
       "2           day_name  0.000000\n",
       "3     flight+airline  0.000000\n",
       "4  flight_no+airline  0.000000\n",
       "5        flight_time  0.400000\n",
       "6     flight+airfare  0.470588\n",
       "7               meal  0.500000\n",
       "8           quantity  0.600000\n",
       "9           aircraft  0.750000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring intents\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9844f858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fromloc.airport_code</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toloc.airport_name</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight_stop</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>depart_time.start_time</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrive_date.date_relative</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>connect</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fromloc.state_name</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flight_days</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flight_time</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fare_amount</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Slot  Score\n",
       "0       fromloc.airport_code    1.0\n",
       "1         toloc.airport_name    1.0\n",
       "2                flight_stop    1.0\n",
       "3     depart_time.start_time    1.0\n",
       "4  arrive_date.date_relative    1.0\n",
       "5                    connect    1.0\n",
       "6         fromloc.state_name    1.0\n",
       "7                flight_days    1.0\n",
       "8                flight_time    1.0\n",
       "9                fare_amount    1.0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best,worst=slots_f1(ATIS_results_test)\n",
    "\n",
    "print(\"10 Best scoring slots\")\n",
    "df = pd.DataFrame(best[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "49dbf30b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>return_date.day_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>compartment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meal_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>airport_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stoploc.airport_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>days_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>booking_class</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>return_time.period_of_day</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Slot  Score\n",
       "0                 state_name    0.0\n",
       "1       return_date.day_name    0.0\n",
       "2                compartment    0.0\n",
       "3                     flight    0.0\n",
       "4                  meal_code    0.0\n",
       "5               airport_code    0.0\n",
       "6       stoploc.airport_code    0.0\n",
       "7                  days_code    0.0\n",
       "8              booking_class    0.0\n",
       "9  return_time.period_of_day    0.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring slots\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbee7f9",
   "metadata": {},
   "source": [
    "#### SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "42762e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GetWeather</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>0.987854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>0.983957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>0.948571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>0.945813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>0.914798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Intent     Score\n",
       "0              RateBook  0.993711\n",
       "1            GetWeather  0.990291\n",
       "2         AddToPlaylist  0.987854\n",
       "3        BookRestaurant  0.983957\n",
       "4             PlayMusic  0.948571\n",
       "5  SearchScreeningEvent  0.945813\n",
       "6    SearchCreativeWork  0.914798"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Best scoring intents\")\n",
    "\n",
    "best,worst=intents_accuracy(SNIPS_intent_test)\n",
    "\n",
    "df = pd.DataFrame(best[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d73f0386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>0.914798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>0.945813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>0.948571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>0.983957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>0.987854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GetWeather</td>\n",
       "      <td>0.990291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Intent     Score\n",
       "0    SearchCreativeWork  0.914798\n",
       "1  SearchScreeningEvent  0.945813\n",
       "2             PlayMusic  0.948571\n",
       "3        BookRestaurant  0.983957\n",
       "4         AddToPlaylist  0.987854\n",
       "5            GetWeather  0.990291\n",
       "6              RateBook  0.993711"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring intents\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6f3cf61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>service</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>object_select</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facility</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>party_size_number</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>current_location</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rating_unit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>movie_type</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>object_location_type</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>best_rating</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Slot  Score\n",
       "0               service    1.0\n",
       "1         object_select    1.0\n",
       "2              facility    1.0\n",
       "3     party_size_number    1.0\n",
       "4      current_location    1.0\n",
       "5                  year    1.0\n",
       "6           rating_unit    1.0\n",
       "7            movie_type    1.0\n",
       "8  object_location_type    1.0\n",
       "9           best_rating    1.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best,worst=slots_f1(SNIPS_results_test)\n",
    "\n",
    "print(\"10 Best scoring slots\")\n",
    "df = pd.DataFrame(best[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c367b8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>album</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>track</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entity_name</td>\n",
       "      <td>0.603175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>restaurant_name</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>geographic_poi</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>served_dish</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movie_name</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>party_size_description</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>poi</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>object_name</td>\n",
       "      <td>0.807947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Slot     Score\n",
       "0                   album  0.260870\n",
       "1                   track  0.315789\n",
       "2             entity_name  0.603175\n",
       "3         restaurant_name  0.606061\n",
       "4          geographic_poi  0.615385\n",
       "5             served_dish  0.692308\n",
       "6              movie_name  0.697674\n",
       "7  party_size_description  0.727273\n",
       "8                     poi  0.750000\n",
       "9             object_name  0.807947"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring slots\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94edc92",
   "metadata": {},
   "source": [
    "### Intent Detection Accuracy by Utterance length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c3d2aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at sentence lenght  2 = 0.5\n",
      "Accuracy at sentence lenght  3 = 0.8181818181818182\n",
      "Accuracy at sentence lenght  4 = 0.9534883720930233\n",
      "Accuracy at sentence lenght  5 = 0.9615384615384616\n",
      "Accuracy at sentence lenght  6 = 0.9473684210526315\n",
      "Accuracy at sentence lenght  7 = 0.9468599033816425\n",
      "Accuracy at sentence lenght  8 = 0.9512987012987013\n",
      "Accuracy at sentence lenght  9 = 0.957345971563981\n",
      "Accuracy at sentence lenght  10 = 0.9649122807017544\n",
      "Accuracy at sentence lenght  11 = 0.9666666666666667\n",
      "Accuracy at sentence lenght  12 = 0.96274217585693\n",
      "Accuracy at sentence lenght  13 = 0.9628610729023384\n",
      "Accuracy at sentence lenght  14 = 0.9636835278858625\n",
      "Accuracy at sentence lenght  15 = 0.9598494353826851\n",
      "Accuracy at sentence lenght  16 = 0.9616766467065868\n",
      "Accuracy at sentence lenght  17 = 0.959349593495935\n",
      "Accuracy at sentence lenght  18 = 0.9583815028901734\n",
      "Accuracy at sentence lenght  19 = 0.9586206896551724\n",
      "Accuracy at sentence lenght  20 = 0.95662100456621\n",
      "Accuracy at sentence lenght  21 = 0.9548532731376975\n",
      "Accuracy at sentence lenght  22 = 0.954954954954955\n",
      "Accuracy at sentence lenght  23 = 0.9550056242969629\n",
      "Accuracy at sentence lenght  29 = 0.9551569506726457\n",
      "Accuracy at sentence lenght  30 = 0.9552071668533034\n",
      "=====================================================================================\n",
      "ATIS  Intent Accuracy by sentence length\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAASzklEQVR4nO3df/Bdd13n8eeLhAqUHwXzxcUmmiopkmFcfsQKCwJL0UkLk6wCTjuisKCdZa3LL3XC4lQs40wBdXXGLt0KCCK0lJ8bJdqigjiOLf22tNA0FEMJNAGaL4joLiOl8vaPc2Iv93vuj7Q3Sb8fno+ZOzk/3t/P+Zz7ufd1zz333JtUFZKkte8+J7oDkqTFMNAlqREGuiQ1wkCXpEYY6JLUCANdkhqxflZBkrcAzwYOV9VjBtYH+D3gbODrwAur6vpZ7W7YsKE2b9581B2WpO9k11133Zeramlo3cxAB94K/D7wRxPWnwVs6W8/Cryx/3eqzZs3s7y8PMfmJUlHJPncpHUzT7lU1UeBf5hSshP4o+pcDZyS5BFH301J0j2xiHPopwK3jcwf7JdJko6j4/qhaJLzkiwnWV5ZWTmem5ak5i0i0A8Bm0bmN/bLVqmqS6tqW1VtW1oaPKcvSbqbFhHou4GfS+eJwNeq6osLaFeSdBTmuWzxMuDpwIYkB4FfB+4LUFWXAHvoLlncT3fZ4n89Vp2VJE02M9Cr6twZ6wv4xYX1SJJ0t/hNUUlqhIEuSY2Y55ui+g6wedcHp64/cNGz5qobrT0WTvT2pXszA/1umDf8vtMdzf10LO7TY/EidSLblGYx0Bvm0Wx71sqLVIvWwv1koPfW0oPVIzpJQwz0Y2wtvKpLaoNXuUhSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjVg/T1GS7cDvAeuAN1XVRWPrvw94G3BKX7OrqvYstqt3z+ZdH5y6/sBFzzpOPZGkY2vmEXqSdcDFwFnAVuDcJFvHyn4NuKKqHgecA/zvRXdUkjTdPKdczgD2V9WtVXUHcDmwc6ymgAf30w8BvrC4LkqS5jFPoJ8K3DYyf7BfNuo1wPOTHAT2AL801FCS85IsJ1leWVm5G92VJE2yqA9FzwXeWlUbgbOBtydZ1XZVXVpV26pq29LS0oI2LUmC+QL9ELBpZH5jv2zUi4ErAKrq74D7ARsW0UFJ0nzmCfRrgS1JTktyEt2HnrvHaj4PnAmQ5NF0ge45FUk6jmYGelXdCZwPXAnso7uaZW+SC5Ps6MteCfxCkhuBy4AXVlUdq05Lklab6zr0/pryPWPLLhiZvhl48mK7Jkk6Gn5TVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij5gr0JNuT3JJkf5JdE2p+OsnNSfYmeediuylJmmX9rIIk64CLgR8HDgLXJtldVTeP1GwBXgU8uaq+muThx6rDkqRh8xyhnwHsr6pbq+oO4HJg51jNLwAXV9VXAarq8GK7KUmaZZ5APxW4bWT+YL9s1OnA6Un+NsnVSbYPNZTkvCTLSZZXVlbuXo8lSYMW9aHoemAL8HTgXOAPkpwyXlRVl1bVtqratrS0tKBNS5JgvkA/BGwamd/YLxt1ENhdVd+sqs8Cn6YLeEnScTJPoF8LbElyWpKTgHOA3WM1H6A7OifJBrpTMLcurpuSpFlmBnpV3QmcD1wJ7AOuqKq9SS5MsqMvuxL4SpKbgQ8Dv1JVXzlWnZYkrTbzskWAqtoD7BlbdsHIdAGv6G+SpBPAb4pKUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhox139wcW+zedcHZ9YcuOhZx6EnknTv4RG6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNWKuQE+yPcktSfYn2TWl7jlJKsm2xXVRkjSPmYGeZB1wMXAWsBU4N8nWgboHAS8Frll0JyVJs81zhH4GsL+qbq2qO4DLgZ0Dda8FXgf8ywL7J0ma0zyBfipw28j8wX7Zv0vyeGBTVU3935uTnJdkOcnyysrKUXdWkjTZPf5QNMl9gN8BXjmrtqouraptVbVtaWnpnm5akjRinkA/BGwamd/YLzviQcBjgI8kOQA8EdjtB6OSdHzNE+jXAluSnJbkJOAcYPeRlVX1taraUFWbq2ozcDWwo6qWj0mPJUmDZgZ6Vd0JnA9cCewDrqiqvUkuTLLjWHdQkjSf9fMUVdUeYM/Ysgsm1D79nndLknS0/KaoJDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEbMFehJtie5Jcn+JLsG1r8iyc1JPpHkL5N8/+K7KkmaZmagJ1kHXAycBWwFzk2ydazs48C2qvph4D3A6xfdUUnSdPMcoZ8B7K+qW6vqDuByYOdoQVV9uKq+3s9eDWxcbDclSbPME+inAreNzB/sl03yYuDPhlYkOS/JcpLllZWV+XspSZppoR+KJnk+sA14w9D6qrq0qrZV1balpaVFblqSvuOtn6PmELBpZH5jv+zbJHkm8GrgaVX1jcV0T5I0r3mO0K8FtiQ5LclJwDnA7tGCJI8D/g+wo6oOL76bkqRZZgZ6Vd0JnA9cCewDrqiqvUkuTLKjL3sD8EDg3UluSLJ7QnOSpGNknlMuVNUeYM/YsgtGpp+54H5Jko6S3xSVpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGzBXoSbYnuSXJ/iS7BtZ/V5J39euvSbJ54T2VJE01M9CTrAMuBs4CtgLnJtk6VvZi4KtV9UjgfwGvW3RHJUnTzXOEfgawv6purao7gMuBnWM1O4G39dPvAc5MksV1U5I0yzyBfipw28j8wX7ZYE1V3Ql8DfjuRXRQkjSfVNX0guS5wPaq+vl+/meBH62q80dqbuprDvbzn+lrvjzW1nnAef3so4BbFrUjwAbgyzOr5q+zzbWx/bXS5one/olus0Un6n76/qpaGlxTVVNvwJOAK0fmXwW8aqzmSuBJ/fT6vvOZ1fYib8DyIutsc21sf620eaK3f6LbbPF2b7yf5jnlci2wJclpSU4CzgF2j9XsBl7QTz8X+Kvq90SSdHysn1VQVXcmOZ/uKHwd8Jaq2pvkQrpXnt3Am4G3J9kP/ANd6EuSjqOZgQ5QVXuAPWPLLhiZ/hfgeYvt2lG7dMF1trk2tr9W2jzR2z/RbbboXnc/zfxQVJK0NvjVf0lqxJoO9CSbknw4yc1J9iZ56ZTa+yX5WJIb+9rfmNH2uiQfT/KnM+oOJPlkkhuSLE+pOyXJe5J8Ksm+JE+aUPeovq0jt39K8rIJtS/v9+WmJJclud+U7b+0r9s73l6StyQ53F9+emTZw5J8KMnf9/8+dELd8/o2v5Vk24w239Dv/yeSvD/JKVNqX9vX3ZDkqiTfO1Q3Uv/KJJVkw5Q2X5Pk0Mh9e/akNpP8Ut/XvUleP6XNd420d6D/d6jusUmuPvI4SXLGlDb/Y5K/6x9Xf5LkwZMe6xPGaVLtt43VlLpV4zSldtU4TXoMrlVT9n1onAZzJt1FJdek+3mUd6W7wGTxTvSlP/fwsqFHAI/vpx8EfBrYOqE2wAP76fsC1wBPnNL2K4B3An86ow8HgA1z9PVtwM/30ycBp8zxN+uAL9Fddzq+7lTgs8D9+/krgBdOaOcxwE3AA+g+N/kL4JEj658KPB64aWTZ64Fd/fQuup9zGKp7NN13Cj4CbJvR5k8A6/vp1wGvm1L74JHp/wFcMlTXr99E96H9546MxYQ2XwP88tjfDtX95/4++q5+/uGTasfa+m3gggltXgWc1U+fDXxkyvavBZ7WT78IeC0THusTxmlS7beN1ZS6VeM0pXbVOJ2ILDiWtyn7PjROgzlD9/w8p19+CfCSY9HXNX2EXlVfrKrr++l/Bvax+lusR2qrqv5fP3vf/jb4AUKSjcCzgDctop9JHkL3xH1z35c7quof5/jTM4HPVNXnJqxfD9w/yXq6sP7ChLpHA9dU1der+ybvXwM/dWRlVX2U7uqkUaM/5/A24L8M1VXVvqpa9QWxCbVX9dsHuBrYOKX2n0ZmT+4WDfYTut8P+lVGxnNK7cx+Ai8BLqqqb/Q1h2e1mSTATwOXTagr4MH99EPox2pC7enAR/vpDwHPmfJYHxqnwdrxsZpSt2qcptSuGqeh+2ctm3LfD43TpJx5Bt3PokA/Tseir2s60Eel+4XHx9G9Ik6qWZfkBuAw8KGqmlT7u3QB8a05Nl3AVUmuS/dN2CGnASvAH6Y7jfOmJCfP0fY5wGWDG606BPwW8Hngi8DXquqqCe3cBPxYku9O8gC6I8RNM7b9PVX1xX76S8D3zNHfo/Ei4M+mFST5zSS3AT9Dd+Q7VLMTOFRVN8653fP7UwRvSfLQCTWn091f1yT56yQ/Mke7PwbcXlV/P2H9y4A39PvzW3Rf0JtkL3f9XtLzGBurscf61HGa53kxo27VOI3XzjNOrRjb98FxGs8Z4DPAP468SA79fMpCNBHoSR4IvBd42dgRw7epqn+tqsfSHRmekeQxA209GzhcVdfNufmnVNXj6X6N8heTPHWgZj3d2+o3VtXjgP9P9/Z42j6dBOwA3j1h/UPpHkynAd8LnJzk+UO1VbWP7m3zVcCfAzcA/zpzz+76+2KBR15JXg3cCbxjxnZfXVWb+rrzx9f3L07/k/lD5I3ADwKPpXsR/O0JdeuBh9G9Vf4V4Ir+CHyac5nw4tt7CfDyfn9eTv9ubYIXAf89yXV0b/HvOLJi2mN9fJzmfV5Mqhsap6HaWePUioF9Hxyn8ZwBfuh49XHNB3qS+9Ldye+oqvfN8zf96Y4PA9sHVj8Z2JHkAN0vSz4jyR9PaetQ/+9h4P10AzjuIHBw5B3Be+gCfpqzgOur6vYJ658JfLaqVqrqm8D7gP80pZ9vrqonVNVTga/SnQec5vYkjwDo/z08o34uSV4IPBv4mT6A5vEO4DkDy3+Q7gXtxn68NgLXJ/kPQ41U1e39k+1bwB8wPFbQjdf7+rfPH6N7p7ZhUuf6U14/Bbxryj68gG6MoHuRnrRtqupTVfUTVfUEuheJz/TbGXqsD47TvM+LSXVD4zRHm5PGac0b2vdJ43TESM48CTilf5xA9zg9dCz6uaYDvT9qejOwr6p+Z0btUu66quL+wI8Dnxqvq6pXVdXGqtpMd8rjr6pq8Mg3yclJHnRkmu7DpFVXYFTVl4DbkjyqX3QmcPOM3Zt1xPd54IlJHtDfD2fSndsblOTh/b/fRxc+75yx/dGfc3gB8H9n1M+UZDvdqawdVfX1GbVbRmZ3MjxWn6yqh1fV5n68DtJ9ePWlCW0+YmT2JxkYq94H6D4YJcnpdB9iT/txpWcCn6r+x+km+ALwtH76GcCkUzOjY3Uf4NeAS6Y81leN07zPi0l1Q+M0pXbmOK11U/Z9aJyGcmYfXbA/t//ThTyfBtW94FPku3sDnkL3FvMTdKcRbgDOnlD7w8DH+9qbgAvmaP/pTLnKBfgB4Mb+thd49ZTaxwLL/fY/ADx0Su3JwFeAh8zo32/QPYFuAt5Of1XGhNq/oXsRuRE4c2zdZXSnIL5JF4ovpvv547+kC56/oDsFMVT3k/30N4Db6X/IbULtfrqfWT4yVpdMqX1vv1+fAP6E7pzjqrqx/TjAXVe5DLX5duCTfZu76a5eGKo7CfjjfvvXA8+Y1Ga//K3Af5txfz4FuK6//68BnjCl9qV076A+DVxEd+XE4GN9wjhNqh0fq2sm1K0apyltrhqnE50LxytnJozTYM7QZcXH+vv23Ux5rt6Tm98UlaRGrOlTLpKkuxjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ14t8A8sc0KbkofeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ATIS\n",
    "intent_hyp,intent_gt,slot_hyp,slot_gt=predict(ATIS_test_loader, ATIS_criterion_slots,\n",
    "                                              ATIS_criterion_intents, ATIS_bigru, ATIS_lang)\n",
    "#Slot is array of array, intent is array of strings\n",
    "\n",
    "#Get an array of (predictions,ground truth) based on utterance length\n",
    "intent_acc_lenght(intent_hyp,intent_gt, ATIS=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3960a853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at sentence lenght  3 = 1.0\n",
      "Accuracy at sentence lenght  4 = 0.9428571428571428\n",
      "Accuracy at sentence lenght  5 = 0.9759036144578314\n",
      "Accuracy at sentence lenght  6 = 0.9565217391304348\n",
      "Accuracy at sentence lenght  7 = 0.9496124031007752\n",
      "Accuracy at sentence lenght  8 = 0.9538904899135446\n",
      "Accuracy at sentence lenght  9 = 0.9577464788732394\n",
      "Accuracy at sentence lenght  10 = 0.9589322381930184\n",
      "Accuracy at sentence lenght  11 = 0.9620253164556962\n",
      "Accuracy at sentence lenght  12 = 0.9645868465430016\n",
      "Accuracy at sentence lenght  13 = 0.9649122807017544\n",
      "Accuracy at sentence lenght  14 = 0.9646697388632872\n",
      "Accuracy at sentence lenght  15 = 0.963963963963964\n",
      "Accuracy at sentence lenght  16 = 0.9648093841642229\n",
      "Accuracy at sentence lenght  17 = 0.965166908563135\n",
      "Accuracy at sentence lenght  18 = 0.9653179190751445\n",
      "Accuracy at sentence lenght  19 = 0.9654178674351584\n",
      "Accuracy at sentence lenght  20 = 0.9655667144906743\n",
      "Accuracy at sentence lenght  21 = 0.9656160458452722\n",
      "Accuracy at sentence lenght  22 = 0.9656652360515021\n",
      "Accuracy at sentence lenght  24 = 0.9657142857142857\n",
      "=====================================================================================\n",
      "SNIPS  Intent Accuracy by sentence length\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SNIPS\n",
    "intent_hyp,intent_gt,slot_hyp,slot_gt=predict(SNIPS_test_loader, SNIPS_criterion_slots,\n",
    "                                              SNIPS_criterion_intents, SNIPS_bigru, SNIPS_lang)\n",
    "#Slot is array of array, intent is array of strings\n",
    "#Get an array of (predictions,ground truth) based on utterance length\n",
    "intent_acc_lenght(intent_hyp,intent_gt, ATIS=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4f939c",
   "metadata": {},
   "source": [
    "# 4) Third Model - Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "465e4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4776ba6",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "62d19239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "max_length=50\n",
    "train_batch_size=16\n",
    "dev_batch_size=8\n",
    "test_batch_size=8\n",
    "epochs=10\n",
    "learning_rate=0.00005\n",
    "hidden_size=768 #Features generated by Bert encoder\n",
    "\n",
    "PRE_TRAINED_MODEL_NAME='bert-base-uncased' #bert pretrained model I want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bd586b",
   "metadata": {},
   "source": [
    "### Bert tokenization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0edfb00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as transformers\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b7f57764",
   "metadata": {},
   "outputs": [],
   "source": [
    "example=\"My name is Jacopo and i would like to book a plane\"\n",
    "encodings=tokenizer.encode_plus(example,add_special_tokens=True,\n",
    "                                max_length=max_length,\n",
    "                               padding='max_length',\n",
    "                               truncation=True,\n",
    "                               return_attention_mask=True,\n",
    "                               return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "17969867",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodings#Starts with CLS(101) and ends with SEP(102)\n",
    "#Contains 3 tensors: input_ids ,token_type_ids ,attention_mask , need all 3 for training\n",
    "#Bert tokenizer separates unknown words, for example Jacopo is broken into 3 separate tokens\n",
    "#Sentence is padded to max_lenght, in this case 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "981cf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.convert_ids_to_tokens(encodings['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f965f",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "Since BERT uses a different token embedding, I've redone the dataloader functions using the BERT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c6c7c155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLang():\n",
    "    def __init__(self, intents, slots):\n",
    "        self.word2id = self.load_bert_dict()\n",
    "        self.slot2id = self.lab2id(slots)\n",
    "        self.intent2id = self.lab2id(intents, pad=False)\n",
    "        self.id2word = {v:k for k, v in self.word2id.items()}\n",
    "        self.id2slot = {v:k for k, v in self.slot2id.items()}\n",
    "        self.id2intent = {v:k for k, v in self.intent2id.items()}\n",
    "        \n",
    "    def load_bert_dict(self):\n",
    "        vocab={}\n",
    "        vocab_file = open('bert_vocab.txt', encoding=\"utf8\")\n",
    "        Lines = vocab_file.readlines()\n",
    "        word_id = 0\n",
    "        for line in Lines:\n",
    "            word=line.rstrip()\n",
    "            vocab[word]=word_id\n",
    "            word_id += 1\n",
    "        return vocab\n",
    "    \n",
    "    def lab2id(self, elements, pad=True):\n",
    "        vocab = {}\n",
    "        if pad:\n",
    "            vocab['pad'] = PAD_TOKEN\n",
    "        for elem in elements:\n",
    "                vocab[elem] = len(vocab)\n",
    "        return vocab\n",
    "    \n",
    "    def print_info(self):\n",
    "        print(\"Vocab size:\",len(self.word2id))\n",
    "        print(\"Slot size:\",len(self.slot2id)-1)\n",
    "        print(\"Number of intents\", len(self.intent2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "12050ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(torch.utils.data.Dataset):\n",
    "    #def __init__(self, dataset, slots, intent, tokenizer, max_len):\n",
    "    def __init__(self, dataset,lang,tokenizer,max_len):\n",
    "        self.utterances = []\n",
    "        self.slots = []\n",
    "        self.intents = []\n",
    "        self.lang=lang\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        for x in dataset:\n",
    "            utterance=x['utterance']\n",
    "            utterance=utterance.replace(\"   \",\" \")#In SNIPS i noticed a problem in the dataset, some sentences have two or morewhitespaces\n",
    "            utterance=utterance.replace(\"  \",\" \")#between words (example \"play a tune or two from kansas city  missouri\"  between city and missouri there are two whitespace)\n",
    "                                                #since bert tokenizer wrongly recognize ' ' as a token, I remove the extra whitespace while loading\n",
    "            self.utterances.append(utterance)\n",
    "            \n",
    "            self.slots.append(x['slots'])\n",
    "            self.intents.append(x['intent'])\n",
    "\n",
    "        self.slot_ids = self.mapping_seq(self.slots, lang.slot2id)\n",
    "        self.intent_ids = self.mapping_lab(self.intents, lang.intent2id)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.utterances)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        utterance = str(self.utterances[item])\n",
    "        lang=self.lang\n",
    "        intent = self.intent_ids[item]\n",
    "        slots = self.slot_ids[item]\n",
    "        slots_len = self.max_len,\n",
    "        sent_len = len(slots)\n",
    "        for i in range(sent_len,self.max_len):\n",
    "            slots.append(PAD_TOKEN)\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "          utterance,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          return_token_type_ids=False,\n",
    "          pad_to_max_length=True,\n",
    "          return_attention_mask=True,\n",
    "          return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "          'utterance': utterance,\n",
    "          'input_ids': encoding['input_ids'].flatten(),\n",
    "          'attention_mask': encoding['attention_mask'].flatten(),#'targets': torch.tensor(target, dtype=torch.long)\n",
    "          'intent': intent,\n",
    "          'slots_len': slots_len,\n",
    "          'slots': torch.tensor(slots, dtype=torch.long)  \n",
    "        }\n",
    "    \n",
    "    def mapping_lab(self, data, mapper):\n",
    "        return [mapper[x] if x in mapper else mapper[self.unk] for x in data]\n",
    "    \n",
    "    def mapping_seq(self, data, mapper): # Map sequences to number\n",
    "        res = []\n",
    "        for seq in data:\n",
    "            tmp_seq = []\n",
    "            for x in seq.split():\n",
    "                if x in mapper:\n",
    "                    tmp_seq.append(mapper[x])\n",
    "                else:\n",
    "                    tmp_seq.append(mapper[self.unk])\n",
    "            res.append(tmp_seq)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "60d32e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATIS_corpus = ATIS_tmp_train_raw + ATIS_test_raw \n",
    "ATIS_slots = set(sum([line['slots'].split() for line in ATIS_corpus],[]))\n",
    "ATIS_intents = set([line['intent'] for line in ATIS_corpus])\n",
    "\n",
    "ATIS_lang = BertLang(ATIS_intents, ATIS_slots)\n",
    "\n",
    "ATIS_train_dataset = BERTDataset(ATIS_train_raw, ATIS_lang, tokenizer, max_length)\n",
    "ATIS_dev_dataset = BERTDataset(ATIS_dev_raw, ATIS_lang, tokenizer, max_length)\n",
    "ATIS_test_dataset = BERTDataset(ATIS_test_raw, ATIS_lang, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f8dff67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNIPS_corpus = SNIPS_train_raw + SNIPS_test_raw \n",
    "SNIPS_slots = set(sum([line['slots'].split() for line in SNIPS_corpus],[]))\n",
    "SNIPS_intents = set([line['intent'] for line in SNIPS_corpus])\n",
    "\n",
    "SNIPS_lang = BertLang(SNIPS_intents, SNIPS_slots)\n",
    "\n",
    "SNIPS_train_dataset = BERTDataset(SNIPS_train_raw, SNIPS_lang, tokenizer, max_length)\n",
    "SNIPS_dev_dataset = BERTDataset(SNIPS_dev_raw, SNIPS_lang, tokenizer, max_length)\n",
    "SNIPS_test_dataset = BERTDataset(SNIPS_test_raw, SNIPS_lang, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "19649a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ATIS_train_dataset.__getitem__(456))\n",
    "\n",
    "#input id traduce la frase con il vocab di bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "e0b04368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATIS\n",
      "Train:  4384\n",
      "Dev:  600\n",
      "Test:  896\n",
      "=====================================================================================\n",
      "SNIPS\n",
      "Train:  13088\n",
      "Dev:  704\n",
      "Test:  704\n"
     ]
    }
   ],
   "source": [
    "def create_data_loader(dataset,batch_size):\n",
    "    return DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "ATIS_train_dataloader = create_data_loader(ATIS_train_dataset, train_batch_size)\n",
    "ATIS_dev_dataloader = create_data_loader(ATIS_dev_dataset, dev_batch_size)\n",
    "ATIS_test_dataloader = create_data_loader(ATIS_test_dataset, test_batch_size)\n",
    "\n",
    "SNIPS_train_dataloader = create_data_loader(SNIPS_train_dataset, train_batch_size)\n",
    "SNIPS_dev_dataloader = create_data_loader(SNIPS_dev_dataset, dev_batch_size)\n",
    "SNIPS_test_dataloader = create_data_loader(SNIPS_test_dataset, test_batch_size)\n",
    "\n",
    "#print(len(ATIS_train_dataloader),train_batch_size)\n",
    "print(\"ATIS\")\n",
    "print(\"Train: \",len(ATIS_train_dataloader)*train_batch_size)\n",
    "print(\"Dev: \",len(ATIS_dev_dataloader)*dev_batch_size)\n",
    "print(\"Test: \",len(ATIS_test_dataloader)*test_batch_size)\n",
    "print(\"=\"*85)\n",
    "print(\"SNIPS\")\n",
    "print(\"Train: \",len(SNIPS_train_dataloader)*train_batch_size)\n",
    "print(\"Dev: \",len(SNIPS_dev_dataloader)*dev_batch_size)\n",
    "print(\"Test: \",len(SNIPS_test_dataloader)*test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d016d",
   "metadata": {},
   "source": [
    "### Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "fccc8831",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertJoint(nn.Module):\n",
    "    def __init__(self,hid_size, out_slot, out_int):\n",
    "        super(BertJoint,self).__init__()\n",
    "        self.bert_encoder= BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=True)\n",
    "        \n",
    "        self.slot_out = nn.Linear(hid_size, out_slot)\n",
    "        self.intent_out = nn.Linear(hid_size, out_int)\n",
    "        #self.dropout=nn.Dropout(0.3)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs= self.bert_encoder(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        #returns sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        \n",
    "        sequence_output = outputs[0]\n",
    "        pooled_output = outputs[1] \n",
    "\n",
    "        intents = self.intent_out(pooled_output)\n",
    "        slots = self.slot_out(sequence_output)\n",
    "        \n",
    "        #Slot size: batch size, seq len, classes\n",
    "        slots = slots.permute(0,2,1) #Used for computing the loss\n",
    "        # Slot size: batch_size, classes, seq_len\n",
    "        \n",
    "        return slots, intents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd8fc4",
   "metadata": {},
   "source": [
    "### Training Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d9f169d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATIS_criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "ATIS_criterion_intents = nn.CrossEntropyLoss()\n",
    "\n",
    "SNIPS_criterion_slots = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN)\n",
    "SNIPS_criterion_intents = nn.CrossEntropyLoss()\n",
    "\n",
    "ATIS_out_slot = len(ATIS_lang.slot2id)\n",
    "ATIS_out_int = len(ATIS_lang.intent2id)\n",
    "ATIS_vocab_len = len(ATIS_lang.word2id)\n",
    "\n",
    "SNIPS_out_slot = len(SNIPS_lang.slot2id)\n",
    "SNIPS_out_int = len(SNIPS_lang.intent2id)\n",
    "SNIPS_vocab_len = len(SNIPS_lang.word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "506255c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertJoint(\n",
       "  (bert_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (slot_out): Linear(in_features=768, out_features=130, bias=True)\n",
       "  (intent_out): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ATIS\n",
    "ATIS_model=BertJoint(hidden_size,ATIS_out_slot,ATIS_out_int)\n",
    "ATIS_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "73e30ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertJoint(\n",
       "  (bert_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (slot_out): Linear(in_features=768, out_features=73, bias=True)\n",
       "  (intent_out): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SNIPS\n",
    "SNIPS_model=BertJoint(hidden_size,SNIPS_out_slot,SNIPS_out_int)\n",
    "SNIPS_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cb254483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ATIS\n",
    "ATIS_optimizer= torch.optim.AdamW(params=ATIS_model.parameters(),lr=learning_rate)\n",
    "ATIS_total_steps=len(ATIS_train_dataloader)*epochs\n",
    "ATIS_scheduler=transformers.get_linear_schedule_with_warmup(ATIS_optimizer,num_warmup_steps=0,num_training_steps=ATIS_total_steps)\n",
    "\n",
    "#SNIPS\n",
    "SNIPS_optimizer= torch.optim.AdamW(params=SNIPS_model.parameters(),lr=learning_rate)\n",
    "SNIPS_total_steps=len(SNIPS_train_dataloader)*epochs\n",
    "SNIPS_scheduler=transformers.get_linear_schedule_with_warmup(SNIPS_optimizer,num_warmup_steps=0,num_training_steps=SNIPS_total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f69469c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,data_loader,intent_criterion,slots_criterion,optimizer,device,scheduler):\n",
    "    \n",
    "    model=model.train()\n",
    "    \n",
    "    loss_array = []\n",
    "    \n",
    "    for d in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_id=d['input_ids'].to(device)\n",
    "        attention_mask=d['attention_mask'].to(device)\n",
    "        intent_gt=d['intent'].to(device)\n",
    "        slot_gt=d['slots'].to(device)\n",
    "        \n",
    "        slot_pred,intent_pred=model(input_ids=input_id, attention_mask=attention_mask)\n",
    "        \n",
    "        loss_intent=intent_criterion(intent_pred,intent_gt)\n",
    "        \n",
    "        loss_slot=slots_criterion(slot_pred,slot_gt)\n",
    "        \n",
    "        #loss=loss_intent+loss_slot\n",
    "        \n",
    "        alpha=random.uniform(0, 1)\n",
    "        beta=1-alpha\n",
    "        \n",
    "        loss=max(alpha,beta) * loss_slot + min(alpha,beta) * loss_intent\n",
    "        \n",
    "        loss_array.append(loss.item())\n",
    "        loss.backward() # Compute the gradient, deleting the computational graph\n",
    "        # clip the gradient to avoid explosioning gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  \n",
    "        optimizer.step() # Update the weights\n",
    "        scheduler.step()\n",
    "        \n",
    "    return loss_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4e5ce6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bert(model, data_loader, intent_criterion,slots_criterion, lang,device):\n",
    "    model = model.eval()\n",
    "    \n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    y_slots = []\n",
    "    hyp_slots = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in data_loader:\n",
    "            input_ids = sample[\"input_ids\"].to(device)\n",
    "            attention_mask = sample[\"attention_mask\"].to(device)\n",
    "            ref_slots = sample[\"slots\"].to(device)\n",
    "            ref_intent = sample[\"intent\"].to(device)\n",
    "\n",
    "            slots, intents = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "            \n",
    "            loss_intent = intent_criterion(intents, ref_intent)\n",
    "            loss_slot = slots_criterion(slots, ref_slots)\n",
    "            loss = loss_intent + loss_slot\n",
    "            \n",
    "            loss_array.append(loss.item())\n",
    "            \n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intent'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            \n",
    "            # Slot inference \n",
    "            output_slots = torch.argmax(slots, dim=1) #Returns the indices of the maximum value of all elements in the input tensor.\n",
    "            ref_slots=ref_slots.tolist()\n",
    "            slots_len=len(ref_slots)\n",
    "            \n",
    "            \n",
    "            for id_seq, seq in enumerate(output_slots):#id_seq è il sample, seq è l'indice dello slot(id dello slot)\n",
    "                length = sample['slots_len'][0].data[0].item()\n",
    "                utterance = sample['utterance'][id_seq].split(\" \")\n",
    "                \n",
    "                gt_ids = sample['slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids]\n",
    "                \n",
    "                #Compute\n",
    "                tmp_ref=[]\n",
    "                for id_el in range(0,length):\n",
    "                    if(id_el<len(utterance)):\n",
    "                        tmp_ref.append((utterance[id_el], gt_slots[id_el]))\n",
    "                y_slots.append(tmp_ref)\n",
    "                \n",
    "                \n",
    "                slot_ids=seq.tolist()\n",
    "                \n",
    "                tmp_seq = []\n",
    "                for id_el in range(0,length):\n",
    "                    if(id_el<len(utterance)):\n",
    "                        tmp_seq.append((utterance[id_el], lang.id2slot[slot_ids[id_el]]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:\n",
    "        results = evaluate(y_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predics a class that is not in REF\n",
    "        print(ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "        \n",
    "    report_intent = classification_report(ref_intents, hyp_intents, \n",
    "                                          zero_division=False, output_dict=True)\n",
    "    return results, report_intent, loss_array                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ee9eb51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_bert(model, data_loader, intent_criterion,slots_criterion, lang,device):\n",
    "    model = model.eval()\n",
    "    \n",
    "    loss_array = []\n",
    "    \n",
    "    ref_intents = []\n",
    "    hyp_intents = []\n",
    "    \n",
    "    y_slots = []\n",
    "    hyp_slots = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in data_loader:\n",
    "            input_ids = sample[\"input_ids\"].to(device)\n",
    "            attention_mask = sample[\"attention_mask\"].to(device)\n",
    "            ref_slots = sample[\"slots\"].to(device)\n",
    "            ref_intent = sample[\"intent\"].to(device)\n",
    "\n",
    "            slots, intents = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "            \n",
    "            loss_intent = intent_criterion(intents, ref_intent)\n",
    "            loss_slot = slots_criterion(slots, ref_slots)\n",
    "            loss = loss_intent + loss_slot\n",
    "            \n",
    "            loss_array.append(loss.item())\n",
    "            \n",
    "            # Intent inference\n",
    "            # Get the highest probable class\n",
    "            out_intents = [lang.id2intent[x] \n",
    "                           for x in torch.argmax(intents, dim=1).tolist()] \n",
    "            gt_intents = [lang.id2intent[x] for x in sample['intent'].tolist()]\n",
    "            ref_intents.extend(gt_intents)\n",
    "            hyp_intents.extend(out_intents)\n",
    "            \n",
    "            \n",
    "            # Slot inference \n",
    "            output_slots = torch.argmax(slots, dim=1) #Returns the indices of the maximum value of all elements in the input tensor.\n",
    "            ref_slots=ref_slots.tolist()\n",
    "            slots_len=len(ref_slots)\n",
    "            \n",
    "            \n",
    "            for id_seq, seq in enumerate(output_slots):#id_seq è il sample, seq è l'indice dello slot(id dello slot)\n",
    "                length = sample['slots_len'][0].data[0].item()\n",
    "                utterance = sample['utterance'][id_seq].split(\" \")\n",
    "                \n",
    "                gt_ids = sample['slots'][id_seq].tolist()\n",
    "                gt_slots = [lang.id2slot[elem] for elem in gt_ids]\n",
    "                \n",
    "                #Compute\n",
    "                tmp_ref=[]\n",
    "                for id_el in range(0,length):\n",
    "                    if(id_el<len(utterance)):\n",
    "                        tmp_ref.append((utterance[id_el], gt_slots[id_el]))\n",
    "                y_slots.append(tmp_ref)\n",
    "                \n",
    "                \n",
    "                slot_ids=seq.tolist()\n",
    "                \n",
    "                tmp_seq = []\n",
    "                for id_el in range(0,length):\n",
    "                    if(id_el<len(utterance)):\n",
    "                        tmp_seq.append((utterance[id_el], lang.id2slot[slot_ids[id_el]]))\n",
    "                hyp_slots.append(tmp_seq)\n",
    "    try:\n",
    "        results = evaluate(y_slots, hyp_slots)\n",
    "    except Exception as ex:\n",
    "        # Sometimes the model predics a class that is not in REF\n",
    "        print(ex)\n",
    "        ref_s = set([x[1] for x in ref_slots])\n",
    "        hyp_s = set([x[1] for x in hyp_slots])\n",
    "        print(hyp_s.difference(ref_s))\n",
    "\n",
    "    return hyp_intents, ref_intents, hyp_slots, y_slots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ad6713",
   "metadata": {},
   "source": [
    "### Training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "16870dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 10.0/100 [00:58<08:46,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss 0.010813026799884945\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                               | 20.0/100 [01:57<07:49,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Train loss 0.011358327950762217\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▋                                                       | 30.0/100 [02:56<06:52,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Train loss 0.011041258845009236\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▌                                               | 40.0/100 [03:55<05:53,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Train loss 0.011156594801785928\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▌                                       | 50.0/100 [04:54<04:54,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train loss 0.010524285995455827\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▍                               | 60.0/100 [05:53<03:56,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "Train loss 0.010824156722417577\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▎                       | 70.0/100 [06:52<02:57,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "Train loss 0.010824754145880142\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▏               | 80.0/100 [07:51<01:58,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "Train loss 0.010919201137229502\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████        | 90.0/100 [08:51<00:59,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "Train loss 0.010993806016886348\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100.0/100 [09:50<00:00,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Train loss 0.011125194435228804\n",
      "Dev Slot F1:  0.9673694779116466\n",
      "Dev Intent Accuracy: 0.9882747068676717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ATIS\n",
    "warnings.filterwarnings('ignore')#Used to ignore a warning from hugging face tokenizer that would get repeated at every epoch, gets displayed only firstime\n",
    "\n",
    "update_tick=100/epochs\n",
    "with tqdm(total=100) as pbar:#updating tqdm manually for clearer visualization\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = train_epoch(\n",
    "        ATIS_model,\n",
    "        ATIS_train_dataloader,\n",
    "        ATIS_criterion_intents,\n",
    "        ATIS_criterion_slots,\n",
    "        ATIS_optimizer,\n",
    "        device,\n",
    "        ATIS_scheduler)\n",
    "\n",
    "        results_dev, intent_res, loss_dev  = eval_bert(\n",
    "        ATIS_model,\n",
    "        ATIS_dev_dataloader,\n",
    "        ATIS_criterion_intents,\n",
    "        ATIS_criterion_slots,\n",
    "        ATIS_lang,\n",
    "        device)\n",
    "\n",
    "        print(\"Epoch:\",epoch)\n",
    "        print(f'Train loss {mean(train_loss)}')\n",
    "        print('Dev Slot F1: ', results_dev['total']['f'])\n",
    "        print('Dev Intent Accuracy:', intent_res['accuracy'])\n",
    "\n",
    "        pbar.update(update_tick)#updating tqdm manually for clearer visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "19910df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 10.0/100 [02:51<25:46, 17.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train loss 0.5427491876472034\n",
      "Slot F1:  0.8361643835616438\n",
      "Intent Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                               | 20.0/100 [05:43<22:52, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Train loss 0.14704721069764937\n",
      "Slot F1:  0.8831814415907208\n",
      "Intent Accuracy: 0.9871428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▋                                                       | 30.0/100 [08:34<20:00, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Train loss 0.09081978900676871\n",
      "Slot F1:  0.9114971050454922\n",
      "Intent Accuracy: 0.9928571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▌                                               | 40.0/100 [11:26<17:09, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Train loss 0.058837612171789455\n",
      "Slot F1:  0.9078366445916114\n",
      "Intent Accuracy: 0.9871428571428571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████████▌                                       | 50.0/100 [14:17<14:17, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Train loss 0.04175392969131178\n",
      "Slot F1:  0.9120575221238938\n",
      "Intent Accuracy: 0.9885714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▍                               | 60.0/100 [17:09<11:26, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\n",
      "Train loss 0.026313311857863588\n",
      "Slot F1:  0.9313698249513754\n",
      "Intent Accuracy: 0.9885714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▎                       | 70.0/100 [20:01<08:34, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\n",
      "Train loss 0.017040726795057085\n",
      "Slot F1:  0.9269241455959989\n",
      "Intent Accuracy: 0.9885714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▏               | 80.0/100 [22:52<05:43, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\n",
      "Train loss 0.010913120792759697\n",
      "Slot F1:  0.9264380530973453\n",
      "Intent Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████        | 90.0/100 [25:44<02:51, 17.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\n",
      "Train loss 0.006802964527016189\n",
      "Slot F1:  0.9319313779745434\n",
      "Intent Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 100.0/100 [28:35<00:00, 17.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\n",
      "Train loss 0.0043981270700585535\n",
      "Slot F1:  0.9368070953436807\n",
      "Intent Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#SNIPS\n",
    "warnings.filterwarnings('ignore')#Used to ignore a warning from hugging face tokenizer that would get repeated at every epoch, gets displayed only firstime\n",
    "\n",
    "update_tick=100/epochs\n",
    "with tqdm(total=100) as pbar:#updating tqdm manually for clearer visualization\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss = train_epoch(\n",
    "        SNIPS_model,\n",
    "        SNIPS_train_dataloader,\n",
    "        SNIPS_criterion_intents,\n",
    "        SNIPS_criterion_slots,\n",
    "        SNIPS_optimizer,\n",
    "        device,\n",
    "        SNIPS_scheduler)\n",
    "\n",
    "\n",
    "        results_dev, intent_res, loss_dev  = eval_bert(\n",
    "        SNIPS_model,\n",
    "        SNIPS_dev_dataloader,\n",
    "        SNIPS_criterion_intents,\n",
    "        SNIPS_criterion_slots,\n",
    "        SNIPS_lang,\n",
    "        device)    \n",
    "    \n",
    "        print(\"Epoch:\",epoch)\n",
    "        print(f'Train loss {mean(train_loss)}')\n",
    "        print('Slot F1: ',results_dev['total']['f'])\n",
    "        print('Intent Accuracy:', intent_res['accuracy'])\n",
    "\n",
    "        pbar.update(update_tick)#updating tqdm manually for clearer visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ca8e3",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ce968b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATIS\n",
      "Slot F1:  0.9205344585091422\n",
      "Intent Accuracy: 0.9776035834266518\n",
      "\n",
      "SNIPS\n",
      "Slot F1:  0.9297026951931093\n",
      "Intent Accuracy: 0.9871428571428571\n"
     ]
    }
   ],
   "source": [
    "ATIS_results_test, ATIS_intent_test, _ = eval_bert(ATIS_model, ATIS_test_dataloader, ATIS_criterion_intents, \n",
    "                                                   ATIS_criterion_slots, ATIS_lang,device)\n",
    "print(\"ATIS\")\n",
    "print('Slot F1: ',ATIS_results_test['total']['f'])\n",
    "print('Intent Accuracy:', ATIS_intent_test['accuracy'])\n",
    "\n",
    "\n",
    "SNIPS_results_test, SNIPS_intent_test, _ = eval_bert(SNIPS_model, SNIPS_test_dataloader, SNIPS_criterion_intents, \n",
    "                                                   SNIPS_criterion_slots, SNIPS_lang,device)\n",
    "\n",
    "print()\n",
    "print(\"SNIPS\")\n",
    "print('Slot F1: ',SNIPS_results_test['total']['f'])\n",
    "print('Intent Accuracy:', SNIPS_intent_test['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993b76b9",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5dc83b",
   "metadata": {},
   "source": [
    "Guarda i worse performing slots, secondo me bert fa fatica a fare slot filling perchè non ho usato un custom vocab, ipotesi verificata se i worse performing label sono nomi di luoghi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b44faf3",
   "metadata": {},
   "source": [
    "### Labels classification performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4bcdcb",
   "metadata": {},
   "source": [
    "#### ATIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4110a4c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aircraft</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capacity</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distance</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>flight_time</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ground_service</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>meal</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flight</td>\n",
       "      <td>0.988161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>airfare</td>\n",
       "      <td>0.979592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>airport</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Intent     Score\n",
       "0        aircraft  1.000000\n",
       "1         airline  1.000000\n",
       "2        capacity  1.000000\n",
       "3        distance  1.000000\n",
       "4     flight_time  1.000000\n",
       "5  ground_service  1.000000\n",
       "6            meal  1.000000\n",
       "7          flight  0.988161\n",
       "8         airfare  0.979592\n",
       "9         airport  0.972973"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Best scoring intents\")\n",
    "\n",
    "best,worst=intents_accuracy(ATIS_intent_test)\n",
    "\n",
    "df = pd.DataFrame(best[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7abcd12f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>airfare+flight</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day_name</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight+airline</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight_no+airline</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quantity</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flight+airfare</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>city</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ground_fare</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flight_no</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abbreviation</td>\n",
       "      <td>0.970588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Intent     Score\n",
       "0     airfare+flight  0.000000\n",
       "1           day_name  0.000000\n",
       "2     flight+airline  0.000000\n",
       "3  flight_no+airline  0.000000\n",
       "4           quantity  0.600000\n",
       "5     flight+airfare  0.631579\n",
       "6               city  0.800000\n",
       "7        ground_fare  0.923077\n",
       "8          flight_no  0.941176\n",
       "9       abbreviation  0.970588"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring intents\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e510443a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flight_stop</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>depart_time.period_mod</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>arrive_date.date_relative</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flight_days</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>connect</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>flight_time</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fromloc.state_code</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>state_code</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cost_relative</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>toloc.state_code</td>\n",
       "      <td>0.972973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Slot     Score\n",
       "0                flight_stop  1.000000\n",
       "1     depart_time.period_mod  1.000000\n",
       "2  arrive_date.date_relative  1.000000\n",
       "3                flight_days  1.000000\n",
       "4                    connect  1.000000\n",
       "5                flight_time  1.000000\n",
       "6         fromloc.state_code  1.000000\n",
       "7                 state_code  1.000000\n",
       "8              cost_relative  0.986301\n",
       "9           toloc.state_code  0.972973"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best,worst=slots_f1(ATIS_results_test)\n",
    "\n",
    "print(\"10 Best scoring slots\")\n",
    "df = pd.DataFrame(best[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "57f76530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>return_date.day_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flight</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compartment</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meal_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>return_date.date_relative</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stoploc.airport_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>toloc.country_name</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>days_code</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>booking_class</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Slot  Score\n",
       "0                 state_name    0.0\n",
       "1       return_date.day_name    0.0\n",
       "2                     flight    0.0\n",
       "3                compartment    0.0\n",
       "4                  meal_code    0.0\n",
       "5  return_date.date_relative    0.0\n",
       "6       stoploc.airport_code    0.0\n",
       "7         toloc.country_name    0.0\n",
       "8                  days_code    0.0\n",
       "9              booking_class    0.0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring slots\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea513a72",
   "metadata": {},
   "source": [
    "#### SNIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5d1e8b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GetWeather</td>\n",
       "      <td>0.995169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>0.994595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>0.988506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>0.971154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Intent     Score\n",
       "0         AddToPlaylist  1.000000\n",
       "1              RateBook  1.000000\n",
       "2            GetWeather  0.995169\n",
       "3        BookRestaurant  0.994595\n",
       "4             PlayMusic  0.988506\n",
       "5  SearchScreeningEvent  0.971154\n",
       "6    SearchCreativeWork  0.963303"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Best scoring intents\")\n",
    "\n",
    "best,worst=intents_accuracy(SNIPS_intent_test)\n",
    "\n",
    "df = pd.DataFrame(best[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9614b0ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring intents\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intent</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SearchScreeningEvent</td>\n",
       "      <td>0.971154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PlayMusic</td>\n",
       "      <td>0.988506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BookRestaurant</td>\n",
       "      <td>0.994595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GetWeather</td>\n",
       "      <td>0.995169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RateBook</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Intent     Score\n",
       "0    SearchCreativeWork  0.963303\n",
       "1  SearchScreeningEvent  0.971154\n",
       "2             PlayMusic  0.988506\n",
       "3        BookRestaurant  0.994595\n",
       "4            GetWeather  0.995169\n",
       "5         AddToPlaylist  1.000000\n",
       "6              RateBook  1.000000"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring intents\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Intent', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "25cea4bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Best scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>party_size_description</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition_description</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>object_select</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facility</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rating_unit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>current_location</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>year</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>object_part_of_series_type</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>genre</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>movie_type</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Slot  Score\n",
       "0      party_size_description    1.0\n",
       "1       condition_description    1.0\n",
       "2               object_select    1.0\n",
       "3                    facility    1.0\n",
       "4                 rating_unit    1.0\n",
       "5            current_location    1.0\n",
       "6                        year    1.0\n",
       "7  object_part_of_series_type    1.0\n",
       "8                       genre    1.0\n",
       "9                  movie_type    1.0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best,worst=slots_f1(SNIPS_results_test)\n",
    "\n",
    "print(\"10 Best scoring slots\")\n",
    "df = pd.DataFrame(best[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "09c28012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Worst scoring slots\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slot</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>album</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cuisine</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>poi</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entity_name</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>movie_name</td>\n",
       "      <td>0.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>object_name</td>\n",
       "      <td>0.858086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>restaurant_name</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>served_dish</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>country</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Slot     Score\n",
       "0            album  0.476190\n",
       "1          cuisine  0.620690\n",
       "2            track  0.636364\n",
       "3              poi  0.705882\n",
       "4      entity_name  0.811594\n",
       "5       movie_name  0.840909\n",
       "6      object_name  0.858086\n",
       "7  restaurant_name  0.875000\n",
       "8      served_dish  0.880000\n",
       "9          country  0.888889"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Worst scoring slots\")\n",
    "df = pd.DataFrame(worst[:10], columns = ['Slot', 'Score'])\n",
    "  \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45cbafe",
   "metadata": {},
   "source": [
    "### Intent Detection Accuracy by Utterance length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "e213da22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at sentence lenght  2 = 0.5\n",
      "Accuracy at sentence lenght  3 = 0.8181818181818182\n",
      "Accuracy at sentence lenght  4 = 0.9534883720930233\n",
      "Accuracy at sentence lenght  5 = 0.9743589743589743\n",
      "Accuracy at sentence lenght  6 = 0.9849624060150376\n",
      "Accuracy at sentence lenght  7 = 0.9806763285024155\n",
      "Accuracy at sentence lenght  8 = 0.9837662337662337\n",
      "Accuracy at sentence lenght  9 = 0.9834123222748815\n",
      "Accuracy at sentence lenght  10 = 0.98635477582846\n",
      "Accuracy at sentence lenght  11 = 0.9883333333333333\n",
      "Accuracy at sentence lenght  12 = 0.9880774962742176\n",
      "Accuracy at sentence lenght  13 = 0.9876203576341128\n",
      "Accuracy at sentence lenght  14 = 0.9857328145265889\n",
      "Accuracy at sentence lenght  15 = 0.9836888331242158\n",
      "Accuracy at sentence lenght  16 = 0.9844311377245509\n",
      "Accuracy at sentence lenght  17 = 0.9814169570267132\n",
      "Accuracy at sentence lenght  18 = 0.9803468208092485\n",
      "Accuracy at sentence lenght  19 = 0.9804597701149426\n",
      "Accuracy at sentence lenght  20 = 0.9794520547945206\n",
      "Accuracy at sentence lenght  21 = 0.9774266365688488\n",
      "Accuracy at sentence lenght  22 = 0.9774774774774775\n",
      "Accuracy at sentence lenght  23 = 0.9775028121484814\n",
      "Accuracy at sentence lenght  29 = 0.9775784753363229\n",
      "Accuracy at sentence lenght  30 = 0.9776035834266518\n",
      "=====================================================================================\n",
      "ATIS  Intent Accuracy by sentence length\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ATIS\n",
    "intent_hyp,intent_gt,slot_hyp,slot_gt=predict_bert(ATIS_model, ATIS_test_dataloader, ATIS_criterion_intents, \n",
    "                                                   ATIS_criterion_slots, ATIS_lang,device)\n",
    "#Slot is array of array, intent is array of strings\n",
    "\n",
    "#Get an array of (predictions,ground truth) based on utterance length\n",
    "intent_acc_lenght(intent_hyp,intent_gt, ATIS=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5090a570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at sentence lenght  3 = 0.8888888888888888\n",
      "Accuracy at sentence lenght  4 = 0.8857142857142857\n",
      "Accuracy at sentence lenght  5 = 0.9518072289156626\n",
      "Accuracy at sentence lenght  6 = 0.968944099378882\n",
      "Accuracy at sentence lenght  7 = 0.9728682170542635\n",
      "Accuracy at sentence lenght  8 = 0.9798270893371758\n",
      "Accuracy at sentence lenght  9 = 0.9812206572769953\n",
      "Accuracy at sentence lenght  10 = 0.9815195071868583\n",
      "Accuracy at sentence lenght  11 = 0.9837251356238698\n",
      "Accuracy at sentence lenght  12 = 0.984822934232715\n",
      "Accuracy at sentence lenght  13 = 0.9856459330143541\n",
      "Accuracy at sentence lenght  14 = 0.9861751152073732\n",
      "Accuracy at sentence lenght  15 = 0.9864864864864865\n",
      "Accuracy at sentence lenght  16 = 0.9868035190615836\n",
      "Accuracy at sentence lenght  17 = 0.9869375907111756\n",
      "Accuracy at sentence lenght  18 = 0.9869942196531792\n",
      "Accuracy at sentence lenght  19 = 0.9870317002881844\n",
      "Accuracy at sentence lenght  20 = 0.9870875179340028\n",
      "Accuracy at sentence lenght  21 = 0.9871060171919771\n",
      "Accuracy at sentence lenght  22 = 0.9871244635193133\n",
      "Accuracy at sentence lenght  24 = 0.9871428571428571\n",
      "=====================================================================================\n",
      "SNIPS  Intent Accuracy by sentence length\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#SNIPS\n",
    "intent_hyp,intent_gt,slot_hyp,slot_gt=predict_bert(SNIPS_model, SNIPS_test_dataloader, SNIPS_criterion_intents, \n",
    "                                                   SNIPS_criterion_slots, SNIPS_lang,device)\n",
    "#Slot is array of array, intent is array of strings\n",
    "\n",
    "#Get an array of (predictions,ground truth) based on utterance length\n",
    "intent_acc_lenght(intent_hyp,intent_gt, ATIS=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14002ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
